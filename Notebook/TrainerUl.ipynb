{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SFcrypt/ColabUI/blob/main/Notebook/TrainerUl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Iniciar Proyecto üßΩ**\n",
        "\n",
        "</details>\n",
        "<img src=\"https://i.pinimg.com/originals/c1/bc/3d/c1bc3d6ba8b7a7c9ff037660e2e4f2c2.gif\" width=\"150%\" height=\"200‚Ä∞\" style=\"margin-bottom: 0;\">\n",
        "\n",
        "Automatiza la creaci√≥n y configuraci√≥n de carpetas en Google Drive, estableciendo una estructura organizada y personalizado para los proyectos de personajes.\n",
        "\n",
        "<small>\n",
        "  <a href=\"https://civitai.com\" target=\"_blank\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/9.0-353535?style=for-the-badge&logo=Github&label=Versi%C3%B3n&labelColor=292929\" alt=\"My Civitai\" width=\"110\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a href=\"https://civitai.com\" target=\"_blank\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/7.0-353535?style=for-the-badge&logo=Pointy&logoColor=%23fafafa&label=Manager&labelColor=292929\" alt=\"My Civitai\" width=\"112\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Disclaimer</font></summary>\n",
        "\n",
        "```diff\n",
        "‚≠ï Descargo de responsabilidad\n",
        "+ Herramientas para gesti√≥n de archivos y proyectos en Google Drive  \n",
        "+ Cumplimiento de las directrices de Google Colab  \n",
        "+ Adherencia a los T√©rminos de servicio de Google Colab  \n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ A√±adido soporte para etiquetado autom√°tico con WaifuDiffusion Tagger  \n",
        "+ Mejorada la interfaz interactiva para filtrar y recortar im√°genes  \n",
        "+ Implementada funci√≥n para renombrar y convertir im√°genes en lote  \n",
        "+ Integrada herramienta para comprimir y descomprimir archivos .zip  \n",
        "+ A√±adido conteo de archivos en carpetas y subcarpetas  \n",
        "+ Simplificada la estructura de carpetas generadas en Google Drive  \n",
        "+ Corregidos errores al montar Google Drive  \n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Optimizaciones en la compresi√≥n y descompresi√≥n de archivos  \n",
        "+ Mejora en la configuraci√≥n inicial de Colab  \n",
        "+ Reducci√≥n del tiempo de instalaci√≥n de dependencias  \n",
        "+ Actualizaciones de bibliotecas cr√≠ticas como `onnxruntime`, `ultralytics`, `Pillow`, y m√°s  \n",
        "+ A√±adido soporte para conteo de archivos espec√≠ficos (im√°genes, textos, modelos)  \n",
        "+ Simplificada la integraci√≥n con Google Drive  \n",
        "+ Mejor manejo de errores al crear carpetas en Google Drive  \n",
        "```"
      ],
      "metadata": {
        "id": "55qNJITqJi3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configurar proyecto\n",
        "\n",
        "#@markdown ### **Configuraci√≥n del proyecto**\n",
        "#@markdown este bloque inicializa el proyecto en google colab, prepara el entorno\n",
        "#@markdown de trabajo y define la estructura principal donde se guardar√°n los archivos.\n",
        "\n",
        "# m√≥dulos necesarios\n",
        "import os, re, io\n",
        "from IPython import get_ipython\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output, display, HTML\n",
        "\n",
        "#@markdown tambi√©n descarga archivos desde **github**\n",
        "#@markdown y muestra mensajes visuales para confirmar que cada paso se complet√≥ correctamente. <p>\n",
        "\n",
        "# conectar google drive\n",
        "if not os.path.exists(\"/content/drive\"):\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# clonar colabui\n",
        "if not os.path.exists(\"ColabUI\"):\n",
        "    !git clone https://github.com/SFcrypt/ColabUI.git\n",
        "    clear_output()\n",
        "\n",
        "# importar widgets visuales (global)\n",
        "from ColabUI.Widgets.gradient_box import (\n",
        "    display_inside_box,\n",
        "    display_outside_box,\n",
        "    display_circular_box)\n",
        "\n",
        "from ColabUI.Widgets.gradient_bar import (\n",
        "    display_ProgressBarAnimated)\n",
        "\n",
        "from ColabUI.Widgets.segsmaker_box import load_segsmaker_style, segsmaker_box\n",
        "load_segsmaker_style()\n",
        "\n",
        "# widget segsmaker\n",
        "nombre_input = widgets.Text(\n",
        "    placeholder=\"Nombre del proyecto\",\n",
        "    layout=widgets.Layout(margin=\"5px 0 15px 0\"))\n",
        "nombre_input.add_class(\"seg-input\")\n",
        "nombre_input.style.placeholder_color = '#d0d0d099'\n",
        "\n",
        "init_btn = widgets.Button(description=\"Crear\")\n",
        "init_btn.add_class(\"seg-button\")\n",
        "\n",
        "# funci√≥n configurar proyecto\n",
        "def configurar_proyecto(b):\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    global ruta_name, ruta_proy\n",
        "\n",
        "    # limpiar nombre: sin espacios y en min√∫sculas\n",
        "    nombre = nombre_input.value.strip().lower()\n",
        "\n",
        "    if not nombre:\n",
        "        raise ValueError(\"error ingresa un nombre v√°lido\")\n",
        "\n",
        "    # definir rutas\n",
        "    ruta_name  = nombre\n",
        "    ruta_drive = \"drive/MyDrive/\"\n",
        "    ruta_proy  = os.path.join(ruta_drive, \"Loras\")\n",
        "    ruta_data  = os.path.join(ruta_proy, ruta_name, \"dataset\")\n",
        "\n",
        "    os.makedirs(ruta_data, exist_ok=True)\n",
        "\n",
        "    # contenedores (no modificar)\n",
        "    clear_output()\n",
        "    contenedor_final = widgets.VBox([\n",
        "        widgets.HBox([widgets.Output(), widgets.Output()]),\n",
        "        widgets.Output()\n",
        "    ])\n",
        "\n",
        "    with contenedor_final.children[0].children[0]:\n",
        "        display_inside_box(\"listo\", left=\"0px\", right=\"0px\", Wide=\"45px\")\n",
        "\n",
        "    with contenedor_final.children[0].children[1]:\n",
        "        display_outside_box(f\"{ruta_name}\", left=\"0px\")\n",
        "\n",
        "    with contenedor_final.children[1]:\n",
        "        display_outside_box(f\"drive/loras/{ruta_name}\", Wide=\"245px\")\n",
        "\n",
        "    display(contenedor_final)\n",
        "\n",
        "init_btn.on_click(configurar_proyecto)\n",
        "\n",
        "# mostrar ui\n",
        "segsmaker_box(\n",
        "    content=[nombre_input, init_btn],\n",
        "    width=\"360px\")\n",
        "\n",
        "# fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4Gu9-Tpz75s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Crear Dataset üí£**\n",
        "[![My Github](https://img.shields.io/badge/GitHub-292929?style=for-the-badge&logo=GitHub)](https://github.com/TuUsuario)\n",
        "[![My Civitai](https://img.shields.io/badge/Colab-%23292929?style=for-the-badge&logo=googlecolab)](https://civitai.com)\n",
        "\n",
        "Herramientas integrales para etiquetar, filtrar, recortar, renombrar, comprimir, descomprimir, y descargar. Optimiza la organizaci√≥n y el procesamiento de tus proyectos con IA y automatizaci√≥n.\n",
        "\n",
        "<small>\n",
        "  <a href=\"https://civitai.com\" target=\"_blank\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/8.0-353535?style=for-the-badge&logo=Github&label=Versi%C3%B3n&labelColor=292929\" alt=\"My Civitai\" width=\"110\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a href=\"https://civitai.com\" target=\"_blank\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/5.5-353535?style=for-the-badge&logo=Pointy&logoColor=%23fafafa&label=Manager&labelColor=292929\" alt=\"My Civitai\" width=\"112\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Disclaimer</font></summary>\n",
        "\n",
        "```diff\n",
        "‚≠ï Descargo de responsabilidad\n",
        "+ Herramientas para gesti√≥n de archivos y proyectos en Google Drive  \n",
        "+ Cumplimiento de las directrices de Google Colab  \n",
        "+ Adherencia a los T√©rminos de servicio de Google Colab  \n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ A√±adido soporte para etiquetado autom√°tico con WaifuDiffusion Tagger  \n",
        "+ Mejorada la interfaz interactiva para filtrar y recortar im√°genes  \n",
        "+ Implementada funci√≥n para renombrar y convertir im√°genes en lote  \n",
        "+ Integrada herramienta para comprimir y descomprimir archivos .zip  \n",
        "+ A√±adido conteo de archivos en carpetas y subcarpetas  \n",
        "+ Simplificada la estructura de carpetas generadas en Google Drive  \n",
        "+ Corregidos errores al montar Google Drive  \n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Optimizaciones en la compresi√≥n y descompresi√≥n de archivos  \n",
        "+ Mejora en la configuraci√≥n inicial de Colab  \n",
        "+ Reducci√≥n del tiempo de instalaci√≥n de dependencias  \n",
        "+ Actualizaciones de bibliotecas cr√≠ticas como `onnxruntime`, `ultralytics`, `Pillow`, y m√°s  \n",
        "+ A√±adido soporte para conteo de archivos espec√≠ficos (im√°genes, textos, modelos)  \n",
        "+ Simplificada la integraci√≥n con Google Drive  \n",
        "+ Mejor manejo de errores al crear carpetas en Google Drive  \n",
        "```"
      ],
      "metadata": {
        "id": "re8AABXU-XNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Comprimir y descargar üì¶**\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/27/2e/99/272e99ff8422acec9e661db5cb717a8b.gif\" width=\"150%\" height=\"230‚Ä∞\" style=\"margin-bottom: 0;\">\n",
        "\n",
        "Descargar, comprimir, descomprimir y contar archivos en tu proyecto de Google Drive. Puedes descargar archivos zip, comprimir carpetas en archivos zip descomprimir archivos zip.\n",
        "\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/3.0-353535?style=for-the-badge&logo=Android&logoColor=%23fafafa&label=Versi√≥n&labelColor=292929\" alt=\"Versi√≥n 1.0\" width=\"100\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/opci√≥nal-353535?style=for-the-badge&logo=Github&label=Paso&labelColor=292929\" alt=\"Google Drive Management\" width=\"115\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Implementaci√≥n de una interfaz interactiva para seleccionar opciones.  \n",
        "+ Soporte para descargar, comprimir y descomprimir archivos en lote.  \n",
        "+ Opci√≥n para contar archivos en carpetas y subcarpetas.  \n",
        "+ Barra de progreso personalizada para el seguimiento de tareas.  \n",
        "```\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Conexi√≥n automatizada a Google Drive desde Google Colab.  \n",
        "+ Creaci√≥n de rutas din√°micas para la organizaci√≥n de archivos.  \n",
        "+ Soporte para formatos de archivo como `.zip`, `.txt`, `.png`, `.jpg`, `.jpeg`, `.safetensors`.  \n",
        "```"
      ],
      "metadata": {
        "id": "SU4fxUHNnwo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar Proyecto\n",
        "\n",
        "#@markdown ### **Descargar proyecto**\n",
        "#@markdown este script permite descargar un archivo .zip desde un link directo de google drive,\n",
        "#@markdown descomprimirlo autom√°ticamente en tu drive y eliminar el zip al finalizar.\n",
        "#@markdown adem√°s, actualiza autom√°ticamente el nombre del `proyecto`\n",
        "#@markdown basado en el archivo zip, incluye barra de progreso personalizada.\n",
        "\n",
        "# M√≥dulos necesarios\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "import io, zipfile, warnings\n",
        "\n",
        "# Autenticaci√≥n para Google Drive\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Widget de Descarga\n",
        "from ColabUI.Widgets.segsmaker_box import load_segsmaker_style, segsmaker_box\n",
        "load_segsmaker_style()\n",
        "\n",
        "link_input = widgets.Text(\n",
        "    placeholder=\"Link del proyecto\",\n",
        "    layout=widgets.Layout(margin=\"5px 0 15px 0\"))\n",
        "link_input.add_class(\"seg-input\")\n",
        "link_input.style.placeholder_color = '#d0d0d099'\n",
        "\n",
        "download_btn = widgets.Button(description=\"Download\")\n",
        "download_btn.add_class(\"seg-button\")\n",
        "\n",
        "# Funci√≥n de descarga mediante widget\n",
        "def descargar_proyecto(b):\n",
        "    clear_output(wait=True)\n",
        "    Link = link_input.value.strip()\n",
        "    if not Link:\n",
        "        return  # nada que descargar\n",
        "\n",
        "    try:\n",
        "        # Extraer ID de Drive\n",
        "        file_id = extract_file_id_from_url(Link)\n",
        "        # Descargar y descomprimir\n",
        "        download_and_extract(file_id, \"\", ruta_drive)\n",
        "    except Exception as e:\n",
        "        display_outside_box(f\"Error: {e}\", Wide=\"265px\")\n",
        "\n",
        "download_btn.on_click(descargar_proyecto)\n",
        "\n",
        "# Mostrar widget\n",
        "segsmaker_box(\n",
        "    content=[link_input, download_btn],\n",
        "    width=\"360px\")\n",
        "\n",
        "# Funci√≥n para extraer ID del archivo desde el link\n",
        "def extract_file_id_from_url(url):\n",
        "    match = re.search(r\"/file/d/([a-zA-Z0-9_-]+)\", url)\n",
        "    if not match: raise Exception(\"‚ùå No se pudo extraer el ID del archivo del enlace.\")\n",
        "    return match.group(1)\n",
        "\n",
        "# Funci√≥n para descargar y descomprimir con barra de progreso\n",
        "def download_and_extract(file_id, nombre, ruta_destino):\n",
        "    global ruta_name  # <--- agregar global para actualizar la variable\n",
        "    file_metadata = drive_service.files().get(fileId=file_id, fields=\"size, name\").execute()\n",
        "    file_size = int(file_metadata['size'])\n",
        "    file_name = file_metadata.get('name', nombre)\n",
        "    output_path = os.path.join(ruta_destino, file_name)\n",
        "\n",
        "    # Barra de progreso\n",
        "    clear_output()\n",
        "    display_outside_box(\"Descargando y descomprimiendo\", Wide=\"300px\")\n",
        "    progress = display_ProgressBarAnimated(\n",
        "        total=file_size,\n",
        "        text=\"\",\n",
        "        width=320,\n",
        "        height=30,\n",
        "        color1=\"#3498db\",\n",
        "        color2=\"#9b59b6\")\n",
        "\n",
        "    # Descargar archivo\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    fh = io.FileIO(output_path, 'wb')\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "    done = False\n",
        "    while not done:\n",
        "        status, done = downloader.next_chunk()\n",
        "        progress.update(int(status.progress() * file_size))\n",
        "\n",
        "    # Descomprimir archivo\n",
        "    with zipfile.ZipFile(output_path, 'r') as zipf:\n",
        "        for i, file_info in enumerate(zipf.infolist()):\n",
        "            zipf.extract(file_info, ruta_destino)\n",
        "\n",
        "    progress.complete(\"Proceso completado\")\n",
        "\n",
        "    clear_output()\n",
        "    display_outside_box(f\"Proyecto descomprimido\", Wide=\"265px\")\n",
        "\n",
        "    # Actualizar ruta_name con el nombre del archivo\n",
        "    ruta_name = os.path.splitext(file_name)[0]\n",
        "\n",
        "    display_outside_box(f\"{ruta_name}\", Wide=\"265px\")\n",
        "    os.remove(output_path)\n",
        "\n",
        "# Ruta donde se guardar√° el proyecto\n",
        "ruta_drive = \"drive/MyDrive/\"\n",
        "\n",
        "#Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8J2nPC7J8FZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comprimir Proyecto\n",
        "\n",
        "#@markdown ### **Comprimir Proyecto**\n",
        "#@markdown Este script permite comprimir la carpeta `dataset` de un proyecto en un archivo .zip.\n",
        "#@markdown La compresi√≥n solo se realizar√° si el proyecto contiene m√°s de 5 im√°genes.\n",
        "#@markdown Esta herramienta es √∫til para respaldar proyectos de manera r√°pida y organizada, asegurando que solo se incluyan archivos de inter√©s. <p>\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# rutas din√°micas\n",
        "ruta_drive = \"drive/MyDrive/\"\n",
        "ruta_proy  = os.path.join(ruta_drive, \"Loras\")\n",
        "ruta_back  = os.path.join(ruta_drive, \"Backup\")\n",
        "ruta_data = os.path.join(ruta_proy, ruta_name, \"dataset\")\n",
        "\n",
        "os.makedirs(ruta_data, exist_ok=True)\n",
        "os.makedirs(ruta_back, exist_ok=True)\n",
        "\n",
        "# Funci√≥n para comprimir la carpeta 'dataset' solo si hay m√°s de 10 im√°genes\n",
        "def comprimir_dataset(ruta_carpeta, ruta_destino_zip):\n",
        "    imagenes = [f for f in os.listdir(ruta_carpeta) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
        "    if len(imagenes) <= 5:\n",
        "        clear_output()\n",
        "        display_outside_box(\"No hay suficientes im√°genes para comprimir el proyecto\", Wide=\"300px\")\n",
        "        return\n",
        "\n",
        "    # Obtener todos los archivos en dataset y subcarpetas\n",
        "    archivos = []\n",
        "    for root, dirs, files in os.walk(ruta_carpeta):\n",
        "        for file in files:\n",
        "            archivos.append(os.path.join(root, file))\n",
        "\n",
        "    total_archivos = len(archivos)\n",
        "\n",
        "    # Barra de progreso\n",
        "    clear_output()\n",
        "    display_outside_box(\"Comprimiendo carpeta dataset...\", Wide=\"300px\")\n",
        "    progress_bar = display_ProgressBarAnimated(\n",
        "        total=total_archivos,\n",
        "        text=\"\",\n",
        "        width=320,\n",
        "        height=30,\n",
        "        color1=\"#3498db\",\n",
        "        color2=\"#9b59b6\")\n",
        "\n",
        "    # Comprimir archivos\n",
        "    with zipfile.ZipFile(ruta_destino_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for i, file_path in enumerate(archivos):\n",
        "            arcname = os.path.join(\n",
        "                \"Loras\",\n",
        "                ruta_name,\n",
        "                \"dataset\",\n",
        "                os.path.relpath(file_path, start=ruta_carpeta)\n",
        "            )\n",
        "            zipf.write(file_path, arcname)\n",
        "            progress_bar.update(1)\n",
        "\n",
        "    progress_bar.complete(\"Compresi√≥n completada\")\n",
        "    clear_output()\n",
        "    display_outside_box(\"Compresi√≥n completada\", Wide=\"265px\")\n",
        "    display_outside_box(f\"{len(imagenes)} im√°genes\", Wide=\"265px\")\n",
        "\n",
        "# Ejecutar compresi√≥n autom√°ticamente si hay suficientes im√°genes\n",
        "ruta_zip = os.path.join(ruta_back, f\"{ruta_name}.zip\")\n",
        "comprimir_dataset(ruta_data, ruta_zip)\n",
        "\n",
        "#Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "iS85Befv8Hv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Estraer capturas üé•**\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/65/87/c0/6587c02f1ff0b4b8686ffc179fcacc1c.gif\" width=\"150%\" height=\"230‚Ä∞\" style=\"margin-bottom: 0;\">\n",
        "\n",
        "Combina dos funcionalidades principales descargar videos desde Google Drive y extraer frames de videos mp4 utilizando FFmpeg, Ofrece una interfaz interactiva para seleccionar archivos.\n",
        "\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/4.0-353535?style=for-the-badge&logo=Android&logoColor=%23fafafa&label=Versi√≥n&labelColor=292929\" alt=\"Versi√≥n 1.0\" width=\"100\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/2-353535?style=for-the-badge&logo=Github&label=Pasos&labelColor=292929\" alt=\"Google Drive Management\" width=\"75\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Interfaz interactiva para seleccionar archivos y configurar opciones.  \n",
        "+ Barras de progreso personalizadas para descargas y extracci√≥n de frames.  \n",
        "+ Soporte para aceleraci√≥n por GPU en la extracci√≥n de frames.  \n",
        "+ Validaci√≥n de permisos y existencia de archivos.  \n",
        "```\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Conexi√≥n automatizada a Google Drive desde Google Colab.  \n",
        "+ Creaci√≥n de rutas din√°micas para descargas y almacenamiento de frames.  \n",
        "+ Integraci√≥n de FFmpeg para la extracci√≥n de frames.  \n",
        "+ Soporte para videos en formato mp4 y gesti√≥n de carpetas en Google Drive.  \n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pEmSPgVntqy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Descargar Videos de Drive\n",
        "\n",
        "#@markdown ### **Descargar video de Drive**\n",
        "#@markdown Este script permite descargar videos desde una carpeta compartida de Google Drive. El usuario puede seleccionar un archivo y descargarlo en una carpeta local o en Google Drive.\n",
        "#@markdown Aseg√∫rate de tener los permisos necesarios para acceder a la carpeta y descargar los archivos.\n",
        "\n",
        "# M√≥dulos necesarios\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "# Autenticaci√≥n para Google Drive\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "# Widget de Descarga\n",
        "from ColabUI.Widgets.segsmaker_box import load_segsmaker_style, segsmaker_box\n",
        "load_segsmaker_style()\n",
        "\n",
        "link_input = widgets.Text(\n",
        "    placeholder=\"Link del video\",\n",
        "    layout=widgets.Layout(margin=\"5px 0 15px 0\"))\n",
        "link_input.add_class(\"seg-input\")\n",
        "link_input.style.placeholder_color = '#d0d0d099'\n",
        "\n",
        "download_btn = widgets.Button(description=\"Download\")\n",
        "download_btn.add_class(\"seg-button\")\n",
        "\n",
        "ruta_video = \"/content/FFmpeg/videos\"\n",
        "os.makedirs(ruta_video, exist_ok=True)\n",
        "\n",
        "# Funci√≥n para extraer el ID del archivo desde el link\n",
        "def extract_file_id_from_url(url):\n",
        "    match = re.search(r\"/file/d/([a-zA-Z0-9_-]+)\", url)\n",
        "    if not match: raise Exception(\"No se pudo extraer el ID\")\n",
        "    return match.group(1)\n",
        "\n",
        "# Funci√≥n para descargar archivo desde Drive\n",
        "def download_from_drive(file_id):\n",
        "    file_metadata = drive_service.files().get(fileId=file_id, fields=\"size, name\").execute()\n",
        "    file_size = int(file_metadata['size'])\n",
        "    file_name = file_metadata['name']\n",
        "\n",
        "    clear_output()\n",
        "    display_outside_box(\"Descargando el video\", Wide=\"300px\")\n",
        "    progress = display_ProgressBarAnimated(\n",
        "        total=file_size,\n",
        "        text=\"\",\n",
        "        width=320,\n",
        "        height=30,\n",
        "        color1=\"#3498db\",\n",
        "        color2=\"#9b59b6\")\n",
        "\n",
        "    request = drive_service.files().get_media(fileId=file_id)\n",
        "    output_path = os.path.join(ruta_video, file_name)\n",
        "    fh = io.FileIO(output_path, 'wb')\n",
        "    downloader = MediaIoBaseDownload(fh, request)\n",
        "    done = False\n",
        "    while not done:\n",
        "        status, done = downloader.next_chunk()\n",
        "        progress.update(int(status.progress() * file_size))\n",
        "\n",
        "    progress.complete(\"Descarga completada\")\n",
        "    clear_output()\n",
        "    display_outside_box(f\"Video descargado\", Wide=\"300px\")\n",
        "\n",
        "# Funci√≥n principal del widget\n",
        "def descargar_video(b):\n",
        "    clear_output()\n",
        "    file_link = link_input.value.strip()\n",
        "    if not file_link:\n",
        "        return\n",
        "    try:\n",
        "        file_id = extract_file_id_from_url(file_link)\n",
        "        download_from_drive(file_id)\n",
        "    except Exception as e:\n",
        "        display_outside_box(f\"Error: {str(e)}\", Wide=\"300px\")\n",
        "\n",
        "download_btn.on_click(descargar_video)\n",
        "\n",
        "# Mostrar widget\n",
        "segsmaker_box(\n",
        "    content=[link_input, download_btn],\n",
        "    width=\"360px\")\n",
        "\n",
        "# Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Tn1MwwA9Y0nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Extracci√≥n de Frames\n",
        "\n",
        "import os, subprocess, shutil\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "#@markdown ### **Extracci√≥n de Frames**\n",
        "#@markdown Este script permite extraer frames de videos mp4 utilizando FFmpeg con aceleraci√≥n por GPU. El usuario puede seleccionar un video de una lista y elegir cu√°ntos frames por segundo `FPS` desea extraer.\n",
        "#@markdown Los frames extra√≠dos se guardar√°n en una carpeta `frames` dentro de tu proyecto, con opci√≥n de dividirlos en subcarpetas.\n",
        "fps_video = 1  # @param {type: \"slider\", min: 0.2, max: 2, step: 0.2}\n",
        "\n",
        "#@markdown El proceso incluye una interfaz interactiva para seleccionar el video, una barra de progreso personalizada y opciones para confirmar o cancelar la extracci√≥n.\n",
        "\n",
        "ruta_drive  = \"drive/MyDrive/\"\n",
        "ruta_video  = \"/content/FFmpeg/videos\"\n",
        "ruta_frame = os.path.join(ruta_drive, \"Capture\")\n",
        "os.makedirs(ruta_frame, exist_ok=True)\n",
        "\n",
        "videos_disponibles = [f for f in os.listdir(ruta_video) if f.endswith('.mp4')]\n",
        "cancel_extraction = False\n",
        "\n",
        "# Opci√≥n para seleccionar el video a procesar\n",
        "if not videos_disponibles:\n",
        "    display_outside_box(\"No se encontraron videos\", \"#DD0700\")\n",
        "else:\n",
        "    seleccion_video = widgets.Dropdown(options=videos_disponibles, description='Selecciona:', disabled=False)\n",
        "    display(seleccion_video)\n",
        "\n",
        "    # Opci√≥n para dividir los frames\n",
        "    dividir_frames = widgets.Dropdown(options=[\"No\", 1, 2, 4, 8], description='Dividir:', disabled=False)\n",
        "    display(dividir_frames)\n",
        "    display_outside_box(\"Selecciona el video a procesar\", Wide=\"265px\")\n",
        "\n",
        "    # Funci√≥n para extraer frames con FFmpeg y GPU\n",
        "    def extract_frames(video_path, output_folder, fps, dividir):\n",
        "        global cancel_extraction\n",
        "        video_name = os.path.splitext(os.path.basename(video_path))[0]  # sin reemplazar espacios\n",
        "\n",
        "        # Carpeta final de frames\n",
        "        subcarpeta_frames = os.path.join(output_folder, video_name)\n",
        "        os.makedirs(subcarpeta_frames, exist_ok=True)\n",
        "\n",
        "        # Obtener la duraci√≥n del video para calcular el progreso\n",
        "        ffprobe_command = [\n",
        "            'ffprobe', '-v', 'error', '-show_entries', 'format=duration',\n",
        "            '-of', 'default=noprint_wrappers=1:nokey=1', video_path\n",
        "        ]\n",
        "        duration = float(subprocess.run(ffprobe_command, stdout=subprocess.PIPE, text=True).stdout.strip())\n",
        "\n",
        "        # Crear la barra de progreso\n",
        "        display_outside_box(\"Extrayendo frames del video...\", Wide=\"300px\")\n",
        "        progress_bar = display_ProgressBarAnimated(\n",
        "            total=int(duration),\n",
        "            text=\"\",\n",
        "            width=320,\n",
        "            height=30,\n",
        "            color1=\"#3498db\",\n",
        "            color2=\"#9b59b6\")\n",
        "\n",
        "        # Comando FFmpeg optimizado GPU + CPU\n",
        "        ffmpeg_command = [\n",
        "            'ffmpeg',\n",
        "            '-hwaccel', 'cuda',        # Usar aceleraci√≥n GPU\n",
        "            '-threads', '0',           # Usar todos los hilos CPU\n",
        "            '-i', video_path,\n",
        "            '-vf', f'fps={fps}',\n",
        "            '-q:v', '1',               # Calidad de los frames\n",
        "            '-preset', 'fast',         # Optimiza velocidad\n",
        "            '-f', 'image2',\n",
        "            os.path.join(subcarpeta_frames, f\"frame %04d.jpg\")\n",
        "        ]\n",
        "\n",
        "        # Ejecutar FFmpeg y actualizar la barra de progreso\n",
        "        try:\n",
        "            process = subprocess.Popen(ffmpeg_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
        "            while True:\n",
        "                output = process.stderr.readline()\n",
        "                if output == '' and process.poll() is not None:\n",
        "                    break\n",
        "                if output:\n",
        "                    # Extraer el tiempo actual del frame procesado\n",
        "                    if \"frame=\" in output and \"time=\" in output:\n",
        "                        time_str = output.split(\"time=\")[1].split(\" \")[0]\n",
        "                        h, m, s = map(float, time_str.split(':'))\n",
        "                        current_time = h * 3600 + m * 60 + s\n",
        "                        progress_bar.update(int(current_time) - progress_bar.current)\n",
        "            process.wait()\n",
        "            if process.returncode == 0:\n",
        "                clear_output(wait=True)  # Borra la salida anterior\n",
        "                progress_bar.complete(\"Extracci√≥n finalizada\")\n",
        "                if dividir != \"No\":\n",
        "                    dividir_frames_en_subcarpetas(subcarpeta_frames, dividir)\n",
        "\n",
        "                display_outside_box(\"Carpeta guardada\", Wide=\"265px\")\n",
        "\n",
        "            else:\n",
        "                clear_output(wait=True)\n",
        "                display_outside_box(\"Error durante la extracci√≥n\", \"#DD0700\")\n",
        "        except KeyboardInterrupt:\n",
        "            process.terminate()\n",
        "            display_outside_box(\"Extracci√≥n cancelada\", \"#DD0700\")\n",
        "\n",
        "    # Funci√≥n para dividir los frames en subcarpetas con barra de progreso\n",
        "    def dividir_frames_en_subcarpetas(carpeta_frames, dividir):\n",
        "        frames = sorted([f for f in os.listdir(carpeta_frames) if f.endswith('.jpg')])\n",
        "        total_frames = len(frames)\n",
        "        frames_por_subcarpeta = total_frames // dividir\n",
        "\n",
        "        # Crear la barra de progreso para la divisi√≥n de frames\n",
        "        display_outside_box(\"Dividiendo frames del video...\", Wide=\"300px\")\n",
        "        progress_bar_div = display_ProgressBarAnimated(\n",
        "            total=total_frames,\n",
        "            text=\"\",\n",
        "            width=320,\n",
        "            height=30,\n",
        "            color1=\"#3498db\",\n",
        "            color2=\"#9b59b6\")\n",
        "\n",
        "        for i in range(dividir):\n",
        "            subcarpeta = os.path.join(carpeta_frames, f\"frames {i+1}\")\n",
        "            os.makedirs(subcarpeta, exist_ok=True)\n",
        "            inicio = i * frames_por_subcarpeta\n",
        "            fin = inicio + frames_por_subcarpeta if i < dividir - 1 else total_frames\n",
        "            for frame in frames[inicio:fin]:\n",
        "                os.rename(os.path.join(carpeta_frames, frame), os.path.join(subcarpeta, frame))\n",
        "                progress_bar_div.update(1)  # Actualizar la barra de progreso\n",
        "\n",
        "        clear_output()\n",
        "        progress_bar_div.complete(\"Divisi√≥n finalizada\")\n",
        "        display_outside_box(\"Extracci√≥n finalizada\", Wide=\"265px\")\n",
        "        display_outside_box(\"Divisi√≥n finalizada\", Wide=\"265px\")\n",
        "\n",
        "    # Funci√≥n para manejar la confirmaci√≥n\n",
        "    def on_start_button_click(b):\n",
        "        global cancel_extraction\n",
        "        cancel_extraction = False\n",
        "        if not seleccion_video.value:\n",
        "            clear_output()\n",
        "            display_outside_box(\"Selecciona un video\", \"#DD0700\")\n",
        "            return\n",
        "        video_path = os.path.join(ruta_video, seleccion_video.value)\n",
        "        if not os.path.exists(video_path):\n",
        "            clear_output()\n",
        "            display_outside_box(\"El video no existe\", \"#DD0700\")\n",
        "            return\n",
        "        clear_output()\n",
        "        extract_frames(video_path, ruta_frame, fps_video, dividir_frames.value)\n",
        "\n",
        "    # Funci√≥n para manejar la cancelaci√≥n\n",
        "    def on_cancel_button_click(b):\n",
        "        global cancel_extraction\n",
        "        cancel_extraction = True\n",
        "        clear_output()\n",
        "        display_outside_box(\"Extracci√≥n cancelada\", \"#DD0700\")\n",
        "\n",
        "    # Mostrar los botones para confirmar o cancelar\n",
        "    start_button = widgets.Button(description=\"Confirmar Extracci√≥n\", button_style='primary', layout=widgets.Layout(width='150px', height='45px'), style={'button_color': '#292929'})\n",
        "    cancel_button = widgets.Button(description=\"Cancelar Extracci√≥n\", button_style='primary', layout=widgets.Layout(width='150px', height='45px'), style={'button_color': '#292929'})\n",
        "    start_button.on_click(on_start_button_click)\n",
        "    cancel_button.on_click(on_cancel_button_click)\n",
        "    display(widgets.HBox([start_button, cancel_button]))\n",
        "\n",
        "# Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Md0VqWw0Y4ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Etiquetar y Editar üè∑Ô∏è**\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/3c/d2/2a/3cd22aba559021ceb78189475ad918f4.gif\" width=\"150%\" height=\"230‚Ä∞\" style=\"margin-bottom: 0;\">\n",
        "\n",
        "Etiquetar autom√°ticamente im√°genes utilizando el modelo WaifuDiffusion Tagger y edita las etiquetas generadas. Las etiquetas se guardan en archivos de texto a cada imagen.\n",
        "\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/4.0-353535?style=for-the-badge&logo=Android&logoColor=%23fafafa&label=Versi√≥n&labelColor=292929\" alt=\"Versi√≥n 1.0\" width=\"100\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/4-353535?style=for-the-badge&logo=Github&label=Paso&labelColor=292929\" alt=\"Google Drive Management\" width=\"75\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Implementaci√≥n de una interfaz interactiva para seleccionar y editar etiquetas.  \n",
        "+ Integraci√≥n del modelo **WaifuDiffusion Tagger** para etiquetado autom√°tico.  \n",
        "+ Opci√≥n para a√±adir nuevas etiquetas personalizadas.  \n",
        "+ Visualizaci√≥n de las etiquetas m√°s comunes con badges interactivos.  \n",
        "```\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Conexi√≥n automatizada a Google Drive desde Google Colab.  \n",
        "+ Creaci√≥n de archivos de texto para almacenar etiquetas.  \n",
        "+ Soporte para formatos de imagen como JPG, PNG y JPEG.  \n",
        "```"
      ],
      "metadata": {
        "id": "y7yLmTCbfyob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Etiquetar Im√°genes\n",
        "\n",
        "#@markdown ### **Etiquetar Im√°genes**\n",
        "#@markdown este script permite etiquetar autom√°ticamente im√°genes utilizando el modelo eva02 large tagger con waifudiffusion.\n",
        "#@markdown las etiquetas generadas incluyen personajes, ropa, expresiones, objetos y rasgos visuales √∫tiles para entrenamiento.\n",
        "\n",
        "umbral = 0.5    # @param {type:\"slider\", min:0.1, max:0.9, step:0.05}\n",
        "umbral_personaje = 0.2\n",
        "umbral_general   = umbral\n",
        "usar_gpu = True\n",
        "\n",
        "#@markdown el proceso incluye una barra de progreso personalizada, soporte para gpu y generaci√≥n autom√°tica de etiquetas listas para lora / sdxl.\n",
        "\n",
        "# dependencias\n",
        "!pip install -q onnxruntime pandas pillow\n",
        "if usar_gpu:\n",
        "    !pip install -q onnxruntime-gpu\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import onnxruntime as rt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# rutas originales del proyecto\n",
        "ruta_waifu = \"/content/WaifuDiffusion/model\"\n",
        "os.makedirs(ruta_waifu, exist_ok=True)\n",
        "\n",
        "model_path = f\"{ruta_waifu}/model.onnx\"\n",
        "labels_path = f\"{ruta_waifu}/selected_tags.csv\"\n",
        "\n",
        "# ruta original del dataset\n",
        "ruta_data = os.path.join(ruta_proy, ruta_name, \"dataset\")\n",
        "os.makedirs(ruta_data, exist_ok=True)\n",
        "\n",
        "# descargar modelo si no existe\n",
        "if not os.path.exists(model_path):\n",
        "    !wget -q https://huggingface.co/SmilingWolf/wd-eva02-large-tagger-v3/resolve/main/model.onnx -O {model_path}\n",
        "\n",
        "if not os.path.exists(labels_path):\n",
        "    !wget -q https://huggingface.co/SmilingWolf/wd-eva02-large-tagger-v3/resolve/main/selected_tags.csv -O {labels_path}\n",
        "\n",
        "# cargar etiquetas\n",
        "kaomojis = [\n",
        "    \"0_0\",\"(o)_(o)\",\"+_+\",\"+-_\",\"._.\",\"<o>_<o>\",\n",
        "    \"=_=\",\">_<\",\"^_^\",\"o_o\",\"u_u\",\"x_x\",\"|_|\"]\n",
        "\n",
        "def load_labels():\n",
        "    df = pd.read_csv(labels_path)\n",
        "    names = df[\"name\"].map(lambda x: x.replace(\"_\",\" \") if x not in kaomojis else x).tolist()\n",
        "    general = np.where(df[\"category\"] == 0)[0]\n",
        "    character = np.where(df[\"category\"] == 4)[0]\n",
        "    return names, general, character\n",
        "\n",
        "tag_names, general_idx, character_idx = load_labels()\n",
        "\n",
        "# modelo\n",
        "class Tagger:\n",
        "    def __init__(self, model_path, usar_gpu=True):\n",
        "        providers = (\n",
        "            [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
        "            if usar_gpu else [\"CPUExecutionProvider\"]\n",
        "        )\n",
        "        self.session = rt.InferenceSession(model_path, providers=providers)\n",
        "        _, h, w, _ = self.session.get_inputs()[0].shape\n",
        "        self.size = h\n",
        "\n",
        "    def prepare(self, image):\n",
        "        image = image.convert(\"RGBA\")\n",
        "        bg = Image.new(\"RGBA\", image.size, (255,255,255))\n",
        "        bg.alpha_composite(image)\n",
        "        image = bg.convert(\"RGB\")\n",
        "\n",
        "        max_dim = max(image.size)\n",
        "        padded = Image.new(\"RGB\", (max_dim, max_dim), (255,255,255))\n",
        "        padded.paste(image, ((max_dim-image.size[0])//2, (max_dim-image.size[1])//2))\n",
        "        padded = padded.resize((self.size, self.size), Image.BICUBIC)\n",
        "\n",
        "        arr = np.asarray(padded, dtype=np.float32)[:, :, ::-1]\n",
        "        return np.expand_dims(arr, 0)\n",
        "\n",
        "    def predict(self, image, thr_general, thr_character):\n",
        "        img = self.prepare(image)\n",
        "        input_name = self.session.get_inputs()[0].name\n",
        "        preds = self.session.run(None, {input_name: img})[0][0]\n",
        "\n",
        "        tg = 1 - thr_general\n",
        "        tc = 1 - thr_character\n",
        "\n",
        "        characters = [tag_names[i] for i in character_idx if preds[i] > tc]\n",
        "        general = [tag_names[i] for i in general_idx if preds[i] > tg]\n",
        "\n",
        "        return \", \".join(characters + general)\n",
        "\n",
        "# procesamiento del dataset con barra de progreso\n",
        "tagger = Tagger(model_path, usar_gpu)\n",
        "image_list = sorted([\n",
        "    f for f in os.listdir(ruta_data)\n",
        "    if f.lower().endswith((\".jpg\",\".jpeg\",\".png\",\".webp\"))])\n",
        "\n",
        "total_images = len(image_list)\n",
        "if total_images == 0:\n",
        "    clear_output()\n",
        "    display_outside_box(\"no se encontraron im√°genes en el dataset\", \"#DD0700\")\n",
        "    raise SystemExit\n",
        "\n",
        "clear_output()\n",
        "display_outside_box(\"etiquetando im√°genes\", Wide=\"300px\")\n",
        "progress_bar = display_ProgressBarAnimated(\n",
        "    total=total_images,\n",
        "    text=\"\",\n",
        "    width=320,\n",
        "    height=30,\n",
        "    color1=\"#3498db\",\n",
        "    color2=\"#9b59b6\")\n",
        "\n",
        "for img_name in image_list:\n",
        "    img_path = os.path.join(ruta_data, img_name)\n",
        "    txt_path = os.path.splitext(img_path)[0] + \".txt\"\n",
        "    image = Image.open(img_path)\n",
        "    tags = tagger.predict(image, umbral_general, umbral_personaje)\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(tags)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "clear_output()\n",
        "progress_bar.complete(\"etiquetado finalizado\")\n",
        "display_outside_box(\"etiquetado finalizado\", Wide=\"265px\")\n",
        "display_outside_box(f\"{total_images} im√°genes etiquetadas\", Wide=\"265px\")\n",
        "\n",
        "#Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aPCK-z9BUOUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Editar Etiquetas\n",
        "\n",
        "#@markdown ### **Editar etiquetas**\n",
        "#@markdown este script permite visualizar imagenes del dataset y editar etiquetas asociadas a cada archivo.\n",
        "#@markdown facilita la navegacion entre imagenes, el guardado automatico de etiquetas y la gestion del progreso.\n",
        "\n",
        "#@markdown incluye herramientas para agregar y eliminar etiquetas individuales o globales de forma sencilla.\n",
        "#@markdown integra enlaces a la wiki de danbooru para consultar informacion de cada etiqueta facilmente.\n",
        "\n",
        "!pip install --upgrade gradio pandas==2.2.2 -q\n",
        "import os, json, gradio as gr, pandas as pd\n",
        "\n",
        "# rutas del dataset\n",
        "ruta_data = os.path.join(ruta_proy, ruta_name, \"dataset\")\n",
        "os.makedirs(ruta_data, exist_ok=True)\n",
        "\n",
        "image_list = sorted([\n",
        "    os.path.join(ruta_data, f)\n",
        "    for f in os.listdir(ruta_data)\n",
        "    if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))\n",
        "])\n",
        "\n",
        "# carpeta para guardar el estado del widget\n",
        "ruta_widget = \"/content/ColabUI\"\n",
        "os.makedirs(ruta_widget, exist_ok=True)\n",
        "state_file = os.path.join(ruta_widget, \"INDEX.md\")\n",
        "\n",
        "def save_index(idx):\n",
        "    with open(state_file, \"w\") as f:\n",
        "        json.dump({\"index\": idx}, f)\n",
        "\n",
        "def load_index():\n",
        "    if os.path.exists(state_file):\n",
        "        return json.load(open(state_file, \"r\")).get(\"index\", 0)\n",
        "    return 0\n",
        "\n",
        "# carga imagen y etiquetas\n",
        "def load_image(idx):\n",
        "    if not image_list:\n",
        "        return None, idx, \"\", \"\", \"\"\n",
        "\n",
        "    idx = idx % len(image_list)\n",
        "    img = image_list[idx]\n",
        "    txt = os.path.splitext(img)[0] + \".txt\"\n",
        "\n",
        "    tags = \"\"\n",
        "    if os.path.exists(txt):\n",
        "        tags = open(txt, \"r\", encoding=\"utf-8\").read()\n",
        "\n",
        "    save_index(idx)\n",
        "    name = os.path.splitext(os.path.basename(img))[0]\n",
        "    return img, idx, tags, \"\", f\"Imagen actual {name}\"\n",
        "\n",
        "\n",
        "# guarda etiquetas actuales\n",
        "def save_current(idx, tags):\n",
        "    if not image_list:\n",
        "        return\n",
        "\n",
        "    txt = os.path.splitext(image_list[idx % len(image_list)])[0] + \".txt\"\n",
        "    with open(txt, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(tags or \"\")\n",
        "\n",
        "\n",
        "def next_image(idx, tags):\n",
        "    save_current(idx, tags)\n",
        "    return load_image(idx + 1)\n",
        "\n",
        "\n",
        "def prev_image(idx, tags):\n",
        "    save_current(idx, tags)\n",
        "    return load_image(idx - 1)\n",
        "\n",
        "\n",
        "# genera link wiki sin comas\n",
        "def generar_link(tag):\n",
        "    if not tag.strip():\n",
        "        return \"\"\n",
        "\n",
        "    clean_tag = tag.replace(\",\", \" \").strip()\n",
        "    url = f\"https://danbooru.donmai.us/wiki_pages/{clean_tag.replace(' ', '_')}\"\n",
        "    return f'<a href=\"{url}\" target=\"_blank\">wiki</a>'\n",
        "\n",
        "\n",
        "# agrega etiqueta a todo el dataset\n",
        "def agregar_tag_dataset(tag):\n",
        "    if not tag.strip():\n",
        "        return \"‚ö†Ô∏è etiqueta vacia\"\n",
        "\n",
        "    for img in image_list:\n",
        "        txt = os.path.splitext(img)[0] + \".txt\"\n",
        "        contenido = open(txt, \"r\", encoding=\"utf-8\").read().strip() if os.path.exists(txt) else \"\"\n",
        "\n",
        "        if not contenido.startswith(tag):\n",
        "            nuevo = f\"{tag}, {contenido}\" if contenido else tag\n",
        "            with open(txt, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(nuevo)\n",
        "\n",
        "    return f\"Etiqueta {tag} agregada al dataset\"\n",
        "\n",
        "\n",
        "# elimina etiqueta del dataset\n",
        "def eliminar_tag_dataset(tag):\n",
        "    if not tag.strip():\n",
        "        return \"‚ö†Ô∏è etiqueta vacia\"\n",
        "\n",
        "    for img in image_list:\n",
        "        txt = os.path.splitext(img)[0] + \".txt\"\n",
        "        contenido = open(txt, \"r\", encoding=\"utf-8\").read().strip() if os.path.exists(txt) else \"\"\n",
        "\n",
        "        tags = [t.strip() for t in contenido.split(\",\") if t.strip() != tag.strip()]\n",
        "        with open(txt, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\", \".join(tags))\n",
        "\n",
        "    return f\"Etiqueta {tag} eliminada del dataset\"\n",
        "\n",
        "# interfaz gradio\n",
        "custom_css = \"\"\"\n",
        "/* quitar color azul al escribir */\n",
        "textarea, textarea:focus {\n",
        "    background-color: var(--input-background-fill) !important;\n",
        "    color: var(--body-text-color) !important;}\n",
        "\n",
        "/* quitar selecci√≥n azul */\n",
        "textarea::selection {\n",
        "    background: #555 !important;\n",
        "    color: #fff !important;}\n",
        "\n",
        "/* para navegadores webkit */\n",
        "textarea::-moz-selection {\n",
        "    background: #555 !important;\n",
        "    color: #fff !important;}\"\"\"\n",
        "\n",
        "with gr.Blocks(theme=\"lone17/kotaemon\", css=custom_css) as demo:\n",
        "    gr.Markdown(\"# üå∏ WaifuDiffusion\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(variant=\"panel\"):\n",
        "            image_in = gr.Image(type=\"filepath\", label=\"imagen\", height=400)\n",
        "\n",
        "            with gr.Accordion(\"Opciones avanzadas\", open=False):\n",
        "                agregar_dataset_btn = gr.Button(\"agregar etiqueta global\")\n",
        "                eliminar_dataset_btn = gr.Button(\"eliminar etiqueta global\")\n",
        "\n",
        "            with gr.Row():\n",
        "                prev_btn = gr.Button(\"Atr√°s\")\n",
        "                next_btn = gr.Button(\"Siguiente\")\n",
        "\n",
        "        with gr.Column(variant=\"panel\"):\n",
        "            with gr.Accordion(\"Ver etiquetas\", open=True):\n",
        "                wiki_tags_box = gr.HTML(\"\")\n",
        "\n",
        "            sorted_out = gr.Textbox(label=\"editar etiquetas\", lines=4)\n",
        "\n",
        "            with gr.Accordion(\"Modificar etiquetas\", open=False):\n",
        "                mostrar_wiki = gr.Checkbox(label=\"mostrar wiki\", value=False)\n",
        "                etiqueta_input = gr.Textbox(label=\"etiqueta\", lines=1)\n",
        "\n",
        "            msg_out = gr.Textbox(label=\"estado\", interactive=False)\n",
        "\n",
        "    index_state = gr.State(load_index())\n",
        "\n",
        "    next_btn.click(\n",
        "        next_image,\n",
        "        inputs=[index_state, sorted_out],\n",
        "        outputs=[image_in, index_state, sorted_out, wiki_tags_box, msg_out],\n",
        "    )\n",
        "\n",
        "    prev_btn.click(\n",
        "        prev_image,\n",
        "        inputs=[index_state, sorted_out],\n",
        "        outputs=[image_in, index_state, sorted_out, wiki_tags_box, msg_out],\n",
        "    )\n",
        "\n",
        "    def actualizar_visualizar(tags, etiqueta, mostrar):\n",
        "        link = generar_link(etiqueta) if mostrar else \"\"\n",
        "        texto = tags.strip()\n",
        "        return f\"{link} {texto}\".strip()\n",
        "\n",
        "    sorted_out.change(\n",
        "        actualizar_visualizar,\n",
        "        inputs=[sorted_out, etiqueta_input, mostrar_wiki],\n",
        "        outputs=[wiki_tags_box],\n",
        "    )\n",
        "\n",
        "    etiqueta_input.change(\n",
        "        actualizar_visualizar,\n",
        "        inputs=[sorted_out, etiqueta_input, mostrar_wiki],\n",
        "        outputs=[wiki_tags_box],\n",
        "    )\n",
        "\n",
        "    mostrar_wiki.change(\n",
        "        actualizar_visualizar,\n",
        "        inputs=[sorted_out, etiqueta_input, mostrar_wiki],\n",
        "        outputs=[wiki_tags_box],\n",
        "    )\n",
        "\n",
        "    agregar_dataset_btn.click(\n",
        "        agregar_tag_dataset,\n",
        "        inputs=[etiqueta_input],\n",
        "        outputs=[msg_out],\n",
        "    )\n",
        "\n",
        "    eliminar_dataset_btn.click(\n",
        "        eliminar_tag_dataset,\n",
        "        inputs=[etiqueta_input],\n",
        "        outputs=[msg_out],\n",
        "    )\n",
        "\n",
        "    demo.load(\n",
        "        lambda: load_image(load_index()),\n",
        "        outputs=[image_in, index_state, sorted_out, wiki_tags_box, msg_out],\n",
        "    )\n",
        "\n",
        "demo.queue()\n",
        "\n",
        "# lanzar app y obtener link publico\n",
        "import re, threading, time, sys, io\n",
        "from IPython.display import clear_output, display\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def launch_and_get_url(demo):\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = mystdout = io.StringIO()\n",
        "\n",
        "    t = threading.Thread(\n",
        "        target=lambda: demo.launch(share=True, prevent_thread_lock=True)\n",
        "    )\n",
        "    t.start()\n",
        "\n",
        "    url = None\n",
        "    while url is None:\n",
        "        time.sleep(1)\n",
        "        output = mystdout.getvalue()\n",
        "        match = re.search(r\"https://[a-z0-9]+\\.gradio\\.live\", output)\n",
        "        if match:\n",
        "            url = match.group(0)\n",
        "\n",
        "    sys.stdout = old_stdout\n",
        "    return url\n",
        "\n",
        "\n",
        "# obtener url\n",
        "app_url = launch_and_get_url(demo)\n",
        "\n",
        "# contenedor visual final\n",
        "contenedor_final = widgets.VBox([\n",
        "    widgets.HBox([\n",
        "        widgets.Output(),\n",
        "        widgets.Output()\n",
        "    ]),\n",
        "    widgets.Output()\n",
        "])\n",
        "\n",
        "with contenedor_final.children[0].children[0]:\n",
        "    display_inside_box(\"listo\", left=\"0px\", right=\"0px\", Wide=\"45px\")\n",
        "\n",
        "with contenedor_final.children[0].children[1]:\n",
        "    display_outside_box(\n",
        "        f'<a href=\"{app_url}\" target=\"_blank\" style=\"text-decoration:none;\">üå∏ WaifuDiffusion</a>',\n",
        "        left=\"0px\")\n",
        "\n",
        "# mostrar resultado final\n",
        "clear_output()\n",
        "display(contenedor_final)\n",
        "\n",
        "#Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gSl7Sb0mUQNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mejorar Im√°genes üó∫Ô∏è**\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/76/9a/f2/769af25c9fbe718c28275465c0c3e34d.gif\" width=\"150%\" height=\"230‚Ä∞\" style=\"margin-bottom: 0;\">\n",
        "\n",
        "Mejorar la calidad, ajustar el tama√±o y reducir la resoluci√≥n de im√°genes. Utiliza modelos Real-ESRGAN para mejorar la calidad y OpenCV para ajustar y reducir el tama√±o de las im√°genes.\n",
        "\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/4.5-353535?style=for-the-badge&logo=Android&logoColor=%23fafafa&label=Versi√≥n&labelColor=292929\" alt=\"Versi√≥n 1.0\" width=\"100\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/3-353535?style=for-the-badge&logo=Github&label=Paso&labelColor=292929\" alt=\"Google Drive Management\" width=\"75\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Implementaci√≥n de una interfaz interactiva para seleccionar opciones.  \n",
        "+ Integraci√≥n de modelos avanzados como Real-ESRGAN y OpenCV.  \n",
        "+ Opci√≥n para reemplazar o guardar im√°genes procesadas en carpetas espec√≠ficas.  \n",
        "+ Barra de progreso personalizada para el seguimiento del procesamiento.  \n",
        "```\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Conexi√≥n automatizada a Google Drive desde Google Colab.  \n",
        "+ Creaci√≥n de rutas din√°micas para la organizaci√≥n de archivos.  \n",
        "+ Soporte para formatos de imagen como JPG, PNG y JPEG.  \n",
        "```\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_59C1GsdpHqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mejorar im√°genes\n",
        "\n",
        "# bloque 1 instalaci√≥n del programa\n",
        "# =================================\n",
        "from ColabUI.Widgets.loading_bars import loading_bars\n",
        "loading_bars(\"Instalando el programa\", padding_left=8)\n",
        "\n",
        "import os, shutil, sys, re, random, numpy as np, torch\n",
        "setup_flag = \"/content/Real-ESRGAN/setup_done.txt\"\n",
        "if not os.path.exists(setup_flag):\n",
        "\n",
        "# instalaci√≥n y configuraci√≥n (ejecuta una vez)\n",
        "    os.system(\"nvidia-smi\")\n",
        "    os.system(\"git clone https://github.com/xinntao/Real-ESRGAN\")\n",
        "    os.chdir(\"/content/Real-ESRGAN\")\n",
        "    os.system(\"pip install basicsr facexlib gfpgan\")\n",
        "    os.system(\"pip install -r requirements.txt\")\n",
        "    os.system(\"python setup.py develop\")\n",
        "\n",
        "    import PIL.Image, IPython.display\n",
        "    from tqdm import tqdm\n",
        "    from google.colab import files\n",
        "    from torch.nn import functional as F\n",
        "\n",
        "    # url de la nueva version de gfpg√°n\n",
        "    new_model_path = 'https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth'\n",
        "    filename = '/content/Real-ESRGAN/inference_realesrgan.py'\n",
        "\n",
        "    # reemplaza la ruta del modelo en el script de inferencia\n",
        "    with open(filename) as f: script = f.read()\n",
        "    script = re.sub(r\"(model_path\\s*=\\s*[\\\"\\']).*?([\\\"\\'])\", rf\"\\1{new_model_path}\\2\", script)\n",
        "    with open(filename,'w') as f: f.write(script)\n",
        "\n",
        "    # corrige importaci√≥n de rgb_to_grayscale\n",
        "    os.system('sed -i \"s/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/\" /usr/local/lib/python3.10/dist-packages/basicsr/data/degradations.py')\n",
        "\n",
        "    # degradations personalizado\n",
        "    degradations_code = '''import cv2, math, random, torch, numpy as np\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def random_add_gaussian_noise_pt(img, sigma_range=(0,1.0), gray_prob=0, noise_gray_prob=0, clip=True, rounds=False):\n",
        "    sigma = random.uniform(*sigma_range)\n",
        "    if random.random()<gray_prob: img=rgb_to_grayscale(img)\n",
        "    noise = (torch.randn(*img.shape[1:],device=img.device).unsqueeze(0).repeat(img.shape[0],1,1)\n",
        "             if random.random()<noise_gray_prob else torch.randn_like(img))*sigma\n",
        "    out = img+noise\n",
        "    if clip and rounds: return torch.clamp((out*255).round(),0,255)/255\n",
        "    if clip: return torch.clamp(out,0,1)\n",
        "    if rounds: return (out*255).round()/255\n",
        "    return out\n",
        "\n",
        "def random_add_poisson_noise_pt(img, scale_range=(0,1.0), gray_prob=0, clip=True, rounds=False):\n",
        "    scale=random.uniform(*scale_range)\n",
        "    if random.random()<gray_prob: img=rgb_to_grayscale(img)\n",
        "    out=img+(torch.poisson(img*scale)/scale-img)\n",
        "    if clip and rounds: return torch.clamp((out*255).round(),0,255)/255\n",
        "    if clip: return torch.clamp(out,0,1)\n",
        "    if rounds: return (out*255).round()/255\n",
        "    return out\n",
        "\n",
        "def rgb_to_grayscale(img):\n",
        "    if img.shape[0]!=3: raise ValueError('input image must have 3 channels')\n",
        "    w=torch.tensor([0.2989,0.5870,0.1140],device=img.device).view(-1,1,1)\n",
        "    return torch.sum(img*w,dim=0,keepdim=True)\n",
        "\n",
        "def circular_lowpass_kernel(cutoff,kernel_size,pad_to=0):\n",
        "    pad_to=pad_to or kernel_size\n",
        "    assert pad_to>=kernel_size\n",
        "    def sinc(x): return torch.tensor(1.) if x==0 else torch.sin(x*math.pi*x)/(x*math.pi*x)\n",
        "    g=torch.linspace(-(kernel_size-1)/2,(kernel_size-1)/2,kernel_size)\n",
        "    x,y=torch.meshgrid(g,g)\n",
        "    k=sinc(torch.sqrt(x**2+y**2)*cutoff); k/=k.sum()\n",
        "    if pad_to>kernel_size: k=F.pad(k,[(pad_to-kernel_size)//2]*4)\n",
        "    return k\n",
        "\n",
        "def random_mixed_kernels(kernel_list,kernel_prob,kernel_size=21,blur_sigma=0.1,blur_sigma_min=0.1,blur_sigma_max=10.0,pad_to=0):\n",
        "    pad_to=pad_to or kernel_size\n",
        "    t=np.random.choice(kernel_list,p=kernel_prob)\n",
        "    if t=='iso': return _iso(kernel_size,np.random.uniform(blur_sigma_min,blur_sigma_max),pad_to)\n",
        "    if t=='aniso': return _aniso(kernel_size,np.random.uniform(blur_sigma_min,blur_sigma_max),\n",
        "                                 np.random.uniform(blur_sigma_min,blur_sigma_max),\n",
        "                                 np.random.uniform(-np.pi,np.pi),pad_to)\n",
        "    return circular_lowpass_kernel(blur_sigma,kernel_size,pad_to)\n",
        "\n",
        "def _iso(k,s,p):\n",
        "    g=torch.linspace(-(k-1)/2,(k-1)/2,k)\n",
        "    x,y=torch.meshgrid(g,g)\n",
        "    k=torch.exp(-(x**2+y**2)/(2*s**2)); k/=k.sum()\n",
        "    return F.pad(k,[(p-k.shape[0])//2]*4) if p>k.shape[0] else k\n",
        "\n",
        "def _aniso(k,sx,sy,r,p):\n",
        "    g=torch.linspace(-(k-1)/2,(k-1)/2,k)\n",
        "    x,y=torch.meshgrid(g,g)\n",
        "    c,s=torch.cos(torch.tensor(r)),torch.sin(torch.tensor(r))\n",
        "    xr,yr=c*x-s*y,s*x+c*y\n",
        "    k=torch.exp(-(xr**2/(2*sx**2)+yr**2/(2*sy**2))); k/=k.sum()\n",
        "    return F.pad(k,[(p-k.shape[0])//2]*4) if p>k.shape[0] else k\n",
        "'''\n",
        "    pyver=f\"python{sys.version_info.major}.{sys.version_info.minor}\"\n",
        "    path=f'/usr/local/lib/{pyver}/dist-packages/basicsr/data/degradations.py'\n",
        "    os.system(f\"cp -n {path} {path}.backup\")\n",
        "    with open(path,'w') as f: f.write(degradations_code)\n",
        "\n",
        "    # crea archivo de bandera\n",
        "    with open(setup_flag, 'w') as f: f.write(\"setup done\")\n",
        "    # print(\"instalaci√≥n y configuraci√≥n completadas\")\n",
        "\n",
        "# Bloque 2 Iniciar proceso de im√°genes\n",
        "# ====================================\n",
        "\n",
        "import os, shutil\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# directorio base\n",
        "os.chdir(\"/content\")\n",
        "upload_folder = \"/content/Real-ESRGAN/upload\"\n",
        "\n",
        "# limpia carpeta temporal\n",
        "shutil.rmtree(upload_folder, ignore_errors=True)\n",
        "os.makedirs(upload_folder)\n",
        "\n",
        "# carpeta din√°mica de entrada\n",
        "ruta_drive = \"/content/drive/MyDrive/\"\n",
        "ruta_proy  = os.path.join(ruta_drive, \"Loras\")\n",
        "ruta_sour = os.path.join(ruta_proy, ruta_name, \"dataset\")\n",
        "\n",
        "# mover im√°genes originales a upload_folder\n",
        "for file in os.listdir(ruta_sour):\n",
        "    shutil.move(os.path.join(ruta_sour, file), upload_folder)\n",
        "\n",
        "#@markdown ### **Mejorar calidad de im√°genes**\n",
        "#@markdown Este script permite mejorar la calidad de im√°genes utilizando el modelo Real-ESRGAN.\n",
        "#@markdown Las im√°genes procesadas se almacenan en Google Drive, organizadas en carpetas espec√≠ficas, y se puede elegir si reemplazar las im√°genes originales tras el procesamiento.\n",
        "\n",
        "# par√°metros del modelo\n",
        "model_name = \"realesr-animevideov3\"\n",
        "escalado = 2  #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "face_enhance = \"No\"\n",
        "\n",
        "#@markdown El usuario tambi√©n puede ajustar el nivel de **escalado** para aumentar la resoluci√≥n de las im√°genes.\n",
        "imagenes = [f for f in os.listdir(upload_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# mostrar mensaje y barra de progreso\n",
        "clear_output()\n",
        "display_outside_box(\"Procesando im√°genes\", Wide=\"300px\")\n",
        "progress_bar = display_ProgressBarAnimated(\n",
        "    total=len(imagenes),\n",
        "    text=\"\",\n",
        "    width=320,\n",
        "    height=30,\n",
        "    color1=\"#3498db\",\n",
        "    color2=\"#9b59b6\")\n",
        "\n",
        "# funci√≥n para procesar una imagen\n",
        "def procesar_imagen(file):\n",
        "    input_path = os.path.join(upload_folder, file)\n",
        "    command = f\"python Real-ESRGAN/inference_realesrgan.py -n {model_name} -i '{input_path}' --outscale {escalado} --output '{ruta_sour}'\"\n",
        "    if face_enhance == \"Yes\":\n",
        "        command += \" --face_enhance\"\n",
        "    os.system(command)\n",
        "    progress_bar.update(1)\n",
        "\n",
        "# procesamiento en paralelo (6 hilos)\n",
        "with ThreadPoolExecutor(max_workers=6) as executor:\n",
        "    futures = [executor.submit(procesar_imagen, file) for file in imagenes]\n",
        "    for future in as_completed(futures):\n",
        "        pass\n",
        "\n",
        "# finalizar barra\n",
        "progress_bar.complete(\"¬°Proceso completado!\")\n",
        "\n",
        "# mostrar resumen visual\n",
        "clear_output()\n",
        "display_outside_box(\"Mejora completada\", Wide=\"265px\")\n",
        "display_outside_box(f\"{len(os.listdir(ruta_sour))} im√°genes procesadas\", Wide=\"265px\")\n",
        "\n",
        "#Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "a5Rcxlp6JnCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@markdown ### **Ajustar tama√±o para Lora**\n",
        "#@markdown Este script ajusta las im√°genes para que el lado m√°s corto siempre sea de **1000 p√≠xeles** (o **2000 p√≠xeles** si se selecciona HD), manteniendo la proporci√≥n original de la imagen.\n",
        "#@markdown Si no se selecciona reemplazar, el nombre de la imagen se modifica con el sufijo `_re`.\n",
        "\n",
        "remplazar_im√°genes = True  # @param {type:\"boolean\"}\n",
        "resolucion_HD = False  # @param {type:\"boolean\"}\n",
        "\n",
        "#@markdown El usuario puede elegir entre una resoluci√≥n est√°ndar (1000 p√≠xeles) o **HD** (2000 p√≠xeles) para el lado m√°s corto.\n",
        "#@markdown Las im√°genes procesadas se almacenan en Google Drive, organizadas en carpetas espec√≠ficas. <br>\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Carpeta de entrada\n",
        "Esrgan_file = os.path.join(project_file, \"dataset\")\n",
        "\n",
        "# Definir lado corto objetivo\n",
        "lado_corto_objetivo = 2000 if resolucion_HD else 1000  # 2000 para HD, 1000 para est√°ndar\n",
        "\n",
        "# Obtener lista de im√°genes en la carpeta\n",
        "image_files = [\n",
        "    filename for filename in os.listdir(Esrgan_file)\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')) and not filename.startswith('.')\n",
        "]\n",
        "\n",
        "# Mostrar mensaje de inicio\n",
        "display_outside_box(\"Procesando im√°genes...\", Wide=\"300px\")\n",
        "\n",
        "# Barra de progreso\n",
        "progress = display_ProgressBarAnimated(\n",
        "    total=len(image_files),\n",
        "    text=\"\",\n",
        "    width=320,\n",
        "    height=30,\n",
        "    color1=\"#3498db\",  # azul\n",
        "    color2=\"#9b59b6\"   # morado\n",
        ")\n",
        "\n",
        "# Funci√≥n para ajustar tama√±o\n",
        "def ajustar_tama√±o(input_path, output_path):\n",
        "    img = cv2.imread(input_path)\n",
        "    if img is None:\n",
        "        print(f\"Error: No se pudo cargar la imagen {input_path}\")\n",
        "        return\n",
        "\n",
        "    altura, ancho = img.shape[:2]\n",
        "\n",
        "    # Escalado basado en el lado corto\n",
        "    lado_corto = min(altura, ancho)\n",
        "    factor_escalado = lado_corto_objetivo / lado_corto\n",
        "\n",
        "    nuevo_ancho = int(ancho * factor_escalado)\n",
        "    nueva_altura = int(altura * factor_escalado)\n",
        "\n",
        "    img_escalada = cv2.resize(img, (nuevo_ancho, nueva_altura), interpolation=cv2.INTER_LANCZOS4)\n",
        "    cv2.imwrite(output_path, img_escalada)\n",
        "\n",
        "# Procesar im√°genes\n",
        "for filename in image_files:\n",
        "    input_path = os.path.join(Esrgan_file, filename)\n",
        "    filename_sin_out = filename.replace('_out', '')\n",
        "\n",
        "    if remplazar_im√°genes:\n",
        "        output_path = input_path\n",
        "    else:\n",
        "        nombre, extension = os.path.splitext(filename_sin_out)\n",
        "        output_path = os.path.join(Esrgan_file, f\"{nombre}_re{extension}\")\n",
        "\n",
        "    ajustar_tama√±o(input_path, output_path)\n",
        "    progress.update(step=1)\n",
        "\n",
        "# Mensaje final\n",
        "clear_output()\n",
        "total_images = len(image_files)\n",
        "if remplazar_im√°genes:\n",
        "    display_outside_box(f\"{total_images} im√°genes ajustadas y reemplazadas.\", Wide=\"300px\")\n",
        "else:\n",
        "    display_outside_box(f\"{total_images} im√°genes ajustadas y guardadas.\", Wide=\"300px\")\n",
        "\n",
        "# Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Zs0QUi_Rh_7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Administrar Archivos üó≥Ô∏è**\n",
        "\n",
        "<img src=\"https://i.pinimg.com/originals/7a/f8/ce/7af8ced6fc14a1f2840b72187ba19248.gif\" width=\"150%\" height=\"230‚Ä∞\" style=\"margin-bottom: 0;\">\n",
        "\n",
        "Renombrar, convertir y eliminar archivos en tu proyecto de Google Drive. Puedes renombrar im√°genes con un nombre personalizado, convertirlas a formato JPG y eliminar archivos.\n",
        "\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/4.5-353535?style=for-the-badge&logo=Android&logoColor=%23fafafa&label=Versi√≥n&labelColor=292929\" alt=\"Versi√≥n 1.0\" width=\"100\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/opci√≥nal-353535?style=for-the-badge&logo=Github&label=Paso&labelColor=292929\" alt=\"Google Drive Management\" width=\"115\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Implementaci√≥n de una interfaz interactiva para seleccionar opciones.  \n",
        "+ Soporte para renombrar y convertir im√°genes en lote.  \n",
        "+ Opci√≥n para eliminar archivos espec√≠ficos (im√°genes, descripciones, registros).  \n",
        "+ Barra de progreso personalizada para el seguimiento de tareas.  \n",
        "```\n",
        "\n",
        "</details>  \n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Conexi√≥n automatizada a Google Drive desde Google Colab.  \n",
        "+ Creaci√≥n de rutas din√°micas para la organizaci√≥n de archivos.  \n",
        "+ Soporte para formatos de imagen como JPG, PNG, JPEG y otros.  \n",
        "```"
      ],
      "metadata": {
        "id": "fUHdPGRTnc3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renombrar Archivos\n",
        "\n",
        "import os\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "from PIL import Image  # Necesitar√°s instalar Pillow: pip install Pillow\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "\n",
        "#@markdown ### **Renombrar y Convertir Im√°genes**\n",
        "#@markdown Puedes renombrar todas las im√°genes de tu proyecto en Google Drive y/o convertirlas a formato JPG.\n",
        "#@markdown Accederemos a los archivos dentro de tu proyecto en Google Drive.\n",
        "\n",
        "convertir_a_jpg = False  #@param {type:\"boolean\"}\n",
        "nombre_personalizado = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "# Descripci√≥n adicional sobre las opciones\n",
        "#@markdown Nombre personalizado Si ingresas un nombre, las im√°genes ser√°n renombradas usando este nombre. Si no ingresas nada, se usar√° el valor de `ruta_n`.\n",
        "\n",
        "#@markdown Convertir a JPG Si eliges esta opci√≥n, las im√°genes que no est√©n en formato JPG ser√°n convertidas a este formato.\n",
        "\n",
        "# Rutas y modelo\n",
        "Esrgan_file = os.path.join(project_file, \"Imagen\")\n",
        "Esrgan_output = Esrgan_file\n",
        "\n",
        "# Crear la carpeta de im√°genes si no existe\n",
        "if not os.path.exists(Esrgan_output):\n",
        "    print(f\"La carpeta {Esrgan_output} no existe. Creando la carpeta...\")\n",
        "    os.makedirs(Esrgan_output)  # Crear la carpeta de im√°genes\n",
        "\n",
        "# Funci√≥n para renombrar archivos de forma ordenada\n",
        "def renombrar_imagenes(nuevo_nombre):\n",
        "    imagenes_renombradas = 0\n",
        "    contador = 1\n",
        "    for root, dirs, files in os.walk(Esrgan_file, topdown=False):\n",
        "        # Filtrar solo im√°genes y ordenar alfab√©ticamente\n",
        "        imagenes = sorted([f for f in files if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
        "        for file in imagenes:\n",
        "            old_file_path = os.path.join(root, file)\n",
        "            extension = os.path.splitext(file)[1]  # Obtener la extensi√≥n del archivo (.jpg, .png, etc.)\n",
        "            # Formato con ceros delante, ej. 01, 02, 03...\n",
        "            new_file_name = f\"{nuevo_nombre} {contador:02d}{extension}\".lower()\n",
        "            new_file_path = os.path.join(root, new_file_name)\n",
        "            os.rename(old_file_path, new_file_path)\n",
        "            imagenes_renombradas += 1\n",
        "            contador += 1\n",
        "    return imagenes_renombradas\n",
        "\n",
        "# Funci√≥n para convertir todas las im√°genes a JPG\n",
        "def convertir_imagenes_a_jpg():\n",
        "    archivos_convertidos = 0\n",
        "    for root, dirs, files in os.walk(Esrgan_file, topdown=False):\n",
        "        for file in files:\n",
        "            if file.endswith(('.png', '.jpeg', '.gif', '.bmp', '.tiff', '.webp')):  # A√±adido para incluir otros tipos de im√°genes\n",
        "                old_file_path = os.path.join(root, file)\n",
        "                new_file_path = os.path.splitext(old_file_path)[0] + '.jpg'\n",
        "\n",
        "                try:\n",
        "                    with Image.open(old_file_path) as img:\n",
        "                        img.convert('RGB').save(new_file_path, 'JPEG')\n",
        "                    os.remove(old_file_path)  # Eliminar el archivo original\n",
        "                    archivos_convertidos += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"No se pudo convertir {file}: {e}\")\n",
        "    return archivos_convertidos\n",
        "\n",
        "# Limpiar la salida si no se ha elegido ninguna opci√≥n\n",
        "if not nombre_personalizado and not convertir_a_jpg:\n",
        "    clear_output()\n",
        "    display_outside_box(\"Elige una opci√≥n\", \"#DD0700\", Wide=\"240px\")\n",
        "else:\n",
        "    # Determinar el nombre a usar\n",
        "    nuevo_nombre = nombre_personalizado if nombre_personalizado else ruta_n\n",
        "\n",
        "    # Inicializar contadores\n",
        "    imagenes_renombradas = 0\n",
        "    archivos_convertidos = 0\n",
        "\n",
        "    # Mostrar barra de progreso\n",
        "    total_archivos = sum([len(files) for _, _, files in os.walk(Esrgan_file)])\n",
        "    progress_bar = display_ProgressBarAnimated(total_archivos, \"Procesando archivos...\")\n",
        "\n",
        "    # Renombrar im√°genes si se ingres√≥ un nombre personalizado o se usa el valor de ruta_n\n",
        "    if nombre_personalizado or not nombre_personalizado:\n",
        "        imagenes_renombradas = renombrar_imagenes(nuevo_nombre)\n",
        "        progress_bar.value = total_archivos // 2  # Simular progreso\n",
        "\n",
        "    # Convertir im√°genes a JPG si se eligi√≥ la opci√≥n\n",
        "    if convertir_a_jpg:\n",
        "        archivos_convertidos = convertir_imagenes_a_jpg()\n",
        "        progress_bar.value = total_archivos  # Completar la barra\n",
        "\n",
        "    # Limpiar la salida\n",
        "    clear_output()\n",
        "\n",
        "    # Mostrar resultados de la acci√≥n\n",
        "    if imagenes_renombradas > 0:\n",
        "        display_outside_box(f\"Im√°genes renombradas: {imagenes_renombradas}\", Wide=\"265px\")\n",
        "    if archivos_convertidos > 0:\n",
        "        display_outside_box(f\"Im√°genes convertidas a JPG: {archivos_convertidos}\", Wide=\"265px\")\n",
        "    if imagenes_renombradas == 0 and archivos_convertidos == 0:\n",
        "        display_outside_box(\"No se ha realizado ninguna acci√≥n\", \"#DD0700\", Wide=\"300px\")\n",
        "\n",
        "#Fin"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DNFIC8YtpEPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0tzRu6xBqj9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# Eliminaci√≥n de Archivos\n",
        "\n",
        "import os\n",
        "from IPython.display import display, Markdown, clear_output, HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "#@markdown ### **Eliminar Archivos**\n",
        "#@markdown Puedes seleccionar qu√© tipo de archivos deseas eliminar de tu proyecto en Google Drive.\n",
        "#@markdown Accederemos a los archivos dentro de tu proyecto en Google Drive.\n",
        "#@markdown - **Im√°genes**: Si eliges esta opci√≥n, se eliminar√°n todos los archivos de im√°genes almacenados en la carpeta de tu proyecto.\n",
        "#@markdown - **Descripciones**: Si eliges esta opci√≥n, se eliminar√°n todos los archivos de texto `txt` que contienen descripciones de tu proyecto.\n",
        "#@markdown - **Registros**: Si eliges esta opci√≥n, se eliminar√°n todos los archivos que no sean im√°genes ni descripciones de la carpeta de tu proyecto.\n",
        "\n",
        "# Caja de informaci√≥n\n",
        "display_outside_box(\"Selecciona los archivos a eliminar\", Wide=\"270px\")\n",
        "\n",
        "# Opciones para seleccionar\n",
        "opciones = ['Im√°genes', 'Descripciones', 'Registros']\n",
        "selector_archivos = widgets.SelectMultiple(\n",
        "    options=opciones,\n",
        "    value=[],\n",
        "    description='',\n",
        "    disabled=False)\n",
        "\n",
        "# Mostrar el selector\n",
        "display(selector_archivos)\n",
        "\n",
        "# Rutas din√°micas\n",
        "Esrgan_file = os.path.join(project_file, \"dataset\")\n",
        "Esrgan_output = Esrgan_file\n",
        "\n",
        "# Validar que la carpeta exista\n",
        "if not os.path.exists(Esrgan_file):\n",
        "    print(f\"‚ùå La carpeta {Esrgan_file} no existe. Creando la carpeta...\")\n",
        "    os.makedirs(Esrgan_file)  # Crear la carpeta de im√°genes\n",
        "\n",
        "# Funci√≥n para borrar archivos\n",
        "def borrar_archivos(tipo):\n",
        "    archivos_borrados = 0  # Contador de archivos borrados\n",
        "    for root, dirs, files in os.walk(Esrgan_file, topdown=False):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if tipo == \"imagenes\" and file.endswith(('.jpg', '.png', '.jpeg')):\n",
        "                os.remove(file_path)\n",
        "                archivos_borrados += 1\n",
        "            elif tipo == \"descripciones\" and file.endswith('.txt'):\n",
        "                os.remove(file_path)\n",
        "                archivos_borrados += 1\n",
        "            elif tipo == \"registros\" and not file.endswith(('.jpg', '.png', '.jpeg', '.txt')):\n",
        "                os.remove(file_path)\n",
        "                archivos_borrados += 1\n",
        "    return archivos_borrados\n",
        "\n",
        "# Funci√≥n para manejar la confirmaci√≥n\n",
        "def on_confirm_button_click(b):\n",
        "    if not selector_archivos.value:\n",
        "        clear_output()\n",
        "        display_outside_box(\"Elige una opci√≥n\", \"#DD0700\", Wide=\"240px\")\n",
        "        return\n",
        "\n",
        "    archivos_borrados_imagenes = 0\n",
        "    archivos_borrados_descripciones = 0\n",
        "    archivos_borrados_registros = 0\n",
        "\n",
        "    # Mostrar barra de progreso\n",
        "    total_archivos = sum([len(files) for _, _, files in os.walk(Esrgan_file)])\n",
        "    progress_bar = display_ProgressBarAnimated(total_archivos, \"Eliminando archivos...\")\n",
        "\n",
        "    if 'Im√°genes' in selector_archivos.value:\n",
        "        archivos_borrados_imagenes = borrar_archivos(\"imagenes\")\n",
        "        progress_bar.value = total_archivos // 3  # Simular progreso\n",
        "\n",
        "    if 'Descripciones' in selector_archivos.value:\n",
        "        archivos_borrados_descripciones = borrar_archivos(\"descripciones\")\n",
        "        progress_bar.value = 2 * total_archivos // 3  # Simular progreso\n",
        "\n",
        "    if 'Registros' in selector_archivos.value:\n",
        "        archivos_borrados_registros = borrar_archivos(\"registros\")\n",
        "        progress_bar.value = total_archivos  # Completar la barra\n",
        "\n",
        "    # Limpiar la salida\n",
        "    clear_output()\n",
        "\n",
        "    # Mostrar resultados de borrado por tipo de archivo\n",
        "    if archivos_borrados_imagenes > 0:\n",
        "        display_outside_box(f\"Im√°genes borradas: {archivos_borrados_imagenes}\", Wide=\"265px\")\n",
        "    if archivos_borrados_descripciones > 0:\n",
        "        display_outside_box(f\"Descripciones borradas: {archivos_borrados_descripciones}\", Wide=\"265px\")\n",
        "    if archivos_borrados_registros > 0:\n",
        "        display_outside_box(f\"Registros borrados: {archivos_borrados_registros}\", Wide=\"265px\")\n",
        "    if archivos_borrados_imagenes == 0 and archivos_borrados_descripciones == 0 and archivos_borrados_registros == 0:\n",
        "        display_outside_box(\"No se han encontrado archivos para borrar\", \"#DD0700\", Wide=\"300px\")\n",
        "\n",
        "# Funci√≥n para manejar la cancelaci√≥n\n",
        "def on_cancel_button_click(b):\n",
        "    clear_output()\n",
        "    display_outside_box(\"Eliminaci√≥n cancelada\", \"#DD0700\", Wide=\"240px\")\n",
        "\n",
        "# Crear botones para continuar o cancelar (con dise√±o similar a Extracci√≥n de Frames)\n",
        "confirm_button = widgets.Button(description=\"Eliminar\", button_style='primary', layout=widgets.Layout(width='150px', height='45px'), style={'button_color': '#292929'})\n",
        "cancel_button = widgets.Button(description=\"Cancelar\", button_style='primary', layout=widgets.Layout(width='150px', height='45px'), style={'button_color': '#292929'})\n",
        "\n",
        "# Asociar las funciones con los botones\n",
        "confirm_button.on_click(on_confirm_button_click)\n",
        "cancel_button.on_click(on_cancel_button_click)\n",
        "\n",
        "# Mostrar los botones para confirmar o cancelar\n",
        "display(widgets.HBox([confirm_button, cancel_button]))\n",
        "\n",
        "# Fin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AdGcZRyPmtm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display, Markdown, clear_output\n",
        "from google.colab import drive\n",
        "\n",
        "#@markdown ### **Contar Archivos**\n",
        "#@markdown Google Drive hace dif√≠cil contar los archivos en una carpeta. Con este c√≥digo, podr√°s ver la cantidad de archivos en las carpetas y subcarpetas de tu Google Drive.\n",
        "\n",
        "#@markdown Accederemos a tu Google Drive y te mostraremos un resumen con el conteo de im√°genes, archivos de texto, modelos y otros archivos.\n",
        "#@markdown  <p> ![My Github](https://img.shields.io/badge/drive%2FMyDrive%2FLoras%2F-292929?style=for-the-badge)\n",
        "\n",
        "# Ruta de la carpeta a contar (modifica seg√∫n sea necesario)\n",
        "carpeta = \"/content/drive/MyDrive/Loras\"\n",
        "#param {type:\"string\"}\n",
        "folder = carpeta\n",
        "\n",
        "# Conectar a Google Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Conectando con Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Funci√≥n para contar los archivos\n",
        "def contar_archivos():\n",
        "    tree = {}\n",
        "    exclude = (\"_logs\", \"/output\")  # Directorios a excluir\n",
        "    for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "        # Excluir carpetas especificadas\n",
        "        dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "        images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "        captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "        modelos = len([f for f in files if f.lower().endswith(\".safetensors\")])\n",
        "        others = len(files) - images - captions - modelos\n",
        "\n",
        "        # Generar ruta completa y evitar duplicados\n",
        "        path = root.replace(folder, \"\").lstrip(\"/\")\n",
        "        full_path = f\"MyDrive/{path}\".replace(\"dataset\", \"\").replace(\"output\", \"\").strip(\"/\")\n",
        "\n",
        "        # Si la carpeta tiene archivos, a√±adirla al diccionario\n",
        "        if images > 0 or captions > 0 or modelos > 0 or others > 0:\n",
        "            if full_path in tree:\n",
        "                tree[full_path] = (\n",
        "                    tree[full_path][0] + images,\n",
        "                    tree[full_path][1] + captions,\n",
        "                    tree[full_path][2] + modelos,\n",
        "                    tree[full_path][3] + others,\n",
        "                )\n",
        "            else:\n",
        "                tree[full_path] = (images, captions, modelos, others)\n",
        "\n",
        "    return tree\n",
        "\n",
        "# Limpiar la salida\n",
        "clear_output()\n",
        "\n",
        "# Contar archivos\n",
        "archivos_contados = contar_archivos()\n",
        "\n",
        "# Calcular el ancho din√°mico para las columnas\n",
        "longest_path = max(len(k) for k in archivos_contados) if archivos_contados else 0\n",
        "col_width = max(25, longest_path + 2)  # Asegura un ancho m√≠nimo de 25\n",
        "\n",
        "# Configurar formato de n√∫meros con ceros a la izquierda (3 d√≠gitos por defecto)\n",
        "def formato_numero(numero):\n",
        "    return str(numero).zfill(3)\n",
        "\n",
        "# Imprimir encabezado\n",
        "print(f\"üóûÔ∏è {'Proyectos'.ljust(col_width)} | {'im√°genes'.center(8)} | {'subt√≠tulos'.center(10)} | {'modelos'.center(10)} | {'otros'.center(6)} |\")\n",
        "print(\"‚îÄ\" * (col_width + 46))  # L√≠nea separadora\n",
        "\n",
        "# Mostrar los resultados\n",
        "for k, v in archivos_contados.items():\n",
        "    if v:\n",
        "        images, captions, modelos, others = v\n",
        "        print(f\"üì¶ {k.ljust(col_width)} | {formato_numero(images).center(8)} | {formato_numero(captions).center(10)} | {formato_numero(modelos).center(10)} | {formato_numero(others).center(6)} |\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Crear Lora ü¶ú**\n",
        "[![My Github](https://img.shields.io/badge/GitHub-292929?style=for-the-badge&logo=GitHub)](https://github.com/TuUsuario)\n",
        "[![My Civitai](https://img.shields.io/badge/Colab-%23292929?style=for-the-badge&logo=googlecolab)](https://civitai.com)\n",
        "\n",
        "Herramientas integrales para etiquetar, filtrar, recortar, renombrar, comprimir, descomprimir, y descargar. Optimiza la organizaci√≥n y el procesamiento de tus proyectos con IA y automatizaci√≥n.\n",
        "\n",
        "<small>\n",
        "  <a href=\"https://civitai.com\" target=\"_blank\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/1.0-353535?style=for-the-badge&logo=Github&label=Versi%C3%B3n&labelColor=292929\" alt=\"My Civitai\" width=\"110\">\n",
        "  </a>\n",
        "</small>\n",
        "<br>\n",
        "<small>\n",
        "  <a href=\"https://civitai.com\" target=\"_blank\" style=\"text-decoration:none;\">\n",
        "    <img src=\"https://img.shields.io/badge/2.5-353535?style=for-the-badge&logo=Pointy&logoColor=%23fafafa&label=Manager&labelColor=292929\" alt=\"My Civitai\" width=\"112\">\n",
        "  </a>\n",
        "</small>\n",
        "\n",
        "---\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Disclaimer</font></summary>\n",
        "\n",
        "```diff\n",
        "‚≠ï Descargo de responsabilidad\n",
        "+ Herramientas para gesti√≥n de archivos y proyectos en Google Drive  \n",
        "+ Cumplimiento de las directrices de Google Colab  \n",
        "+ Adherencia a los T√©rminos de servicio de Google Colab  \n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>√öltimos cambios</font></summary>\n",
        "\n",
        "```diff\n",
        "+ A√±adido soporte para etiquetado autom√°tico con WaifuDiffusion Tagger  \n",
        "+ Mejorada la interfaz interactiva para filtrar y recortar im√°genes  \n",
        "+ Implementada funci√≥n para renombrar y convertir im√°genes en lote  \n",
        "+ Integrada herramienta para comprimir y descomprimir archivos .zip  \n",
        "+ A√±adido conteo de archivos en carpetas y subcarpetas  \n",
        "+ Simplificada la estructura de carpetas generadas en Google Drive  \n",
        "+ Corregidos errores al montar Google Drive  \n",
        "```\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "  <summary><font color=gray>Cambios antiguos</font></summary>\n",
        "\n",
        "```diff\n",
        "+ Optimizaciones en la compresi√≥n y descompresi√≥n de archivos  \n",
        "+ Mejora en la configuraci√≥n inicial de Colab  \n",
        "+ Reducci√≥n del tiempo de instalaci√≥n de dependencias  \n",
        "+ Actualizaciones de bibliotecas cr√≠ticas como `onnxruntime`, `ultralytics`, `Pillow`, y m√°s  \n",
        "+ A√±adido soporte para conteo de archivos espec√≠ficos (im√°genes, textos, modelos)  \n",
        "+ Simplificada la integraci√≥n con Google Drive  \n",
        "+ Mejor manejo de errores al crear carpetas en Google Drive  \n",
        "```"
      ],
      "metadata": {
        "id": "MgLaj0Tb_S28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, toml, pathlib, warnings, shutil\n",
        "from time import time\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Estado de ejecuciones previas\n",
        "project_name = ruta_n\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "old_model_url = model_url if \"model_url\" in globals() else None\n",
        "dependencies_installed = globals().get(\"dependencies_installed\", False)\n",
        "model_file = globals().get(\"model_file\", None)\n",
        "\n",
        "# Variables heredadas / opcionales\n",
        "custom_dataset = globals().get(\"custom_dataset\")\n",
        "override_dataset_config_file = globals().get(\"override_dataset_config_file\")\n",
        "override_config_file = globals().get(\"override_config_file\")\n",
        "continue_from_lora = globals().get(\"continue_from_lora\", \"\")\n",
        "\n",
        "# Configuraci√≥n general\n",
        "COLAB = True\n",
        "SOURCE = \"https://github.com/qaneel/kohya-trainer\"\n",
        "COMMIT = None\n",
        "\n",
        "BETTER_EPOCH_NAMES = True\n",
        "LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Detectar si hay poca RAM menos de 15 GB\n",
        "try:\n",
        "    LOWRAM = int(next(l.split()[1] for l in open(\"/proc/meminfo\") if \"MemTotal\" in l)) / 1024**2 < 15\n",
        "except Exception:\n",
        "    LOWRAM = False\n",
        "\n",
        "#@markdown ### **Procesamiento**\n",
        "#@markdown Decide el modelo que se descargar√° y se usar√° para entrenamiento\n",
        "#@markdown Usar un modelo diffusers consume menos recursos. Las 3 opciones funcionar√°n con o sin diffusers.\n",
        "\n",
        "# Modelo base para entrenamiento\n",
        "Modelo_Entrenamiento = \"WAI Illustrious V15\"  #@param [\"Blender XL\", \"Illustrious XL\", \"Margarita V2\", \"Animagine V3\", \"WAI Illustrious V15\"]\n",
        "training_model = Modelo_Entrenamiento\n",
        "\n",
        "# Usar diffusers reduce consumo de memoria\n",
        "load_diffusers = True\n",
        "wandb_key = None\n",
        "\n",
        "# Selecci√≥n de modelo\n",
        "if \"Blender XL\" in training_model:\n",
        "    model_file = \"/content/BlenderXL.safetensors\"\n",
        "    model_url = (\n",
        "        \"https://huggingface.co/ParahumanSkitter/Blender-XL-Illustrious-V10\"\n",
        "        if load_diffusers else\n",
        "        \"https://civitai.com/api/download/models/1637657\")\n",
        "\n",
        "elif \"DarkMix V2\" in training_model:\n",
        "    model_file = \"/content/DarkMixV2.safetensors\"\n",
        "    model_url = (\n",
        "        \"https://huggingface.co/John6666/darkmix-margarita-illustrious-photo-fantastical-realism-v200-sdxl\"\n",
        "        if load_diffusers else\n",
        "        \"https://civitai.com/api/download/models/1675329\")\n",
        "\n",
        "elif \"Animagine V3\" in training_model:\n",
        "    model_file = \"/content/animagineXLV3.safetensors\"\n",
        "    model_url = (\n",
        "        \"https://huggingface.co/cagliostrolab/animagine-xl-3.0\"\n",
        "        if load_diffusers else\n",
        "        \"https://civitai.com/api/download/models/293564\")\n",
        "\n",
        "elif \"WAI Illustrious V15\" in training_model:\n",
        "    model_file = \"/content/Illustrious.safetensors\"\n",
        "    model_url = (\n",
        "        \"https://huggingface.co/Ine007/waiIllustriousSDXL_v150\"\n",
        "        if load_diffusers else\n",
        "        \"https://civitai.com/api/download/models/2167369\")\n",
        "\n",
        "# modelo base\n",
        "else:\n",
        "    model_file = \"/content/IllustriousXL_Base.safetensors\"\n",
        "    model_url = (\n",
        "        \"https://huggingface.co/glides/illustriousxl\"\n",
        "        if load_diffusers else\n",
        "        \"https://civitai.com/api/download/models/889818\")\n",
        "\n",
        "# Modelo VAE\n",
        "model_url = model_url.strip()\n",
        "vae_file = \"stabilityai/sdxl-vae\" if load_diffusers else \"/content/sdxl_vae.safetensors\"\n",
        "if not load_diffusers: vae_url = \"https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\"\n",
        "\n",
        "#@markdown ### **Etiquetas**\n",
        "#@markdown Mezclar etiquetas de anime en su lugar mejora el aprendizaje y el prompting. Una etiqueta de activaci√≥n va al inicio de cada archivo de texto y no se mezclar√°.\n",
        "resolution = 1024  #param {type:\"slider\", min:768, max:1536, step:128}\n",
        "caption_extension = \".txt\"\n",
        "\n",
        "# Etiquetas de activaci√≥n\n",
        "shuffle_tags = True\n",
        "shuffle_caption = True\n",
        "Activaci√≥n = \"1\"  #@param [0,1,2,3]\n",
        "activation_tags = Activaci√≥n\n",
        "keep_tokens = int(activation_tags)\n",
        "\n",
        "#@markdown ### **Pasos**\n",
        "#@markdown Tus im√°genes se repetir√°n durante el entrenamiento. Recomiendo que sean alrededor de `50` `im√°genes`.\n",
        "Repeticiones = 8  #@param {type:\"number\"}\n",
        "num_repeats = Repeticiones\n",
        "\n",
        "#@markdown ### **√âpocas**\n",
        "#@markdown Elige cu√°nto tiempo quieres entrenar. Un buen punto de partida es alrededor de 10 √©pocas o 500 pasos,\n",
        "#@markdown Una √©poca es un n√∫mero de pasos igual a: tu n√∫mero de im√°genes multiplicado por sus repeticiones, y la cantidad de `.safetensors` a crear.<p>\n",
        "preferred_unit = \"√âpocas\"\n",
        "Cantidad_√âpocas = 4  #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "how_many = Cantidad_√âpocas\n",
        "max_train_epochs = how_many if preferred_unit == \"√âpocas\" else None\n",
        "max_train_steps = how_many if preferred_unit == \"Pasos\" else None\n",
        "\n",
        "#@markdown Guardar m√°s √©pocas te permitir√° comparar mejor el progreso de tu LoRA.\n",
        "save_every_n_epochs = 1\n",
        "keep_only_last_n_epochs = Cantidad_√âpocas\n",
        "save_every_n_epochs = save_every_n_epochs or max_train_epochs\n",
        "keep_only_last_n_epochs = keep_only_last_n_epochs or max_train_epochs\n",
        "\n",
        "#@markdown ### **Aprendizaje**\n",
        "#@markdown El scheduler es el algoritmo que gu√≠a la tasa de aprendizaje. Si no est√°s seguro, elige `constant` y ignora el n√∫mero. Recomiendo `cosine_with_restarts` con 3 reinicios.\n",
        "Scheduler = \"cosine_with_restarts\"  #@param [\"constant\", \"cosine\", \"cosine_with_restarts\", \"constant_with_warmup\", \"linear\", \"polynomial\"]\n",
        "lr_scheduler = Scheduler\n",
        "lr_scheduler_number = 3\n",
        "\n",
        "# UNet: controla qu√© tan r√°pido se actualizan los pesos de la red principal que genera las im√°genes.\n",
        "# Text Encoder: controla qu√© tan r√°pido se ajusta el codificador de texto que interpreta los prompts.\n",
        "unet_lr = 3e-4\n",
        "text_encoder_lr = 4e-5\n",
        "\n",
        "# Fracci√≥n de pasos iniciales usados para \"calentar\" el aprendizaje\n",
        "lr_warmup_ratio = 0.1\n",
        "lr_warmup_steps = 0\n",
        "\n",
        "#@markdown Ajusta la p√©rdida con el tiempo, haciendo el aprendizaje m√°s eficiente. El paper recomienda 5.0, recomiendo 8.0 para anime. Valores mayores lo hacen menos estricto. Pon 0 para desactivar.\n",
        "Aprendizaje = 5  #@param {type:\"slider\", min:0.0, max:10.0, step:0.5}\n",
        "min_snr_gamma = Aprendizaje\n",
        "\n",
        "# Multinoise puede ayudar con el balance de color.\n",
        "multinoise = True\n",
        "\n",
        "#@markdown ###  **Estructura**\n",
        "#@markdown LoRA es el tipo cl√°sico y bueno para una variedad de prop√≥sitos. LoCon es bueno con estilos art√≠sticos ya que tiene m√°s capas para aprender m√°s aspectos del dataset.\n",
        "Tipo_de_lora = \"LoRA\"  #@param [\"LoRA\", \"LoCon\"]\n",
        "lora_type = Tipo_de_lora\n",
        "\n",
        "#@markdown | tipo |  tama√±o dim  |  tama√±o alpha  |\n",
        "#@markdown | :------: | :------: | :------: |\n",
        "#@markdown | LoRA regular |  16  |  32  |\n",
        "#@markdown | LoCon estilo |  8  |  16  |\n",
        "\n",
        "#@markdown M√°s dim significa LoRA m√°s grande, puede almacenar m√°s informaci√≥n pero m√°s no siempre es mejor.\n",
        "# Slider combinado para network_dim y network_alpha (network_alpha = 2 * network_dim)\n",
        "Tama√±o_de_lora = 8  #@param {type:\"slider\", min:2, max:16, step:2}\n",
        "conv_dim = Tama√±o_de_lora\n",
        "conv_alpha = conv_dim * 2\n",
        "\n",
        "# Slider combinado para network_alpha y conv_alpha\n",
        "network_dim = conv_alpha\n",
        "network_alpha = conv_dim\n",
        "network_module = \"networks.lora\"\n",
        "network_args = [f\"conv_dim={conv_dim}\", f\"conv_alpha={conv_alpha}\"] if lora_type.lower() == \"locon\" else None\n",
        "\n",
        "#@markdown ### **Entrenamiento**\n",
        "#@markdown Ajusta estos par√°metros seg√∫n la configuraci√≥n de tu Colab.\n",
        "#@markdown Si est√°s usando la versi√≥n gratuita, deber√≠as seleccionar un modelo diffusers al inicio de esta celda.\n",
        "#@markdown Un batch size m√°s alto suele ser m√°s r√°pido pero usa m√°s memoria.\n",
        "Tama√±o_de_entrenamiento = 4  #@param {type:\"slider\", min:1, max:5, step:1}\n",
        "train_batch_size = Tama√±o_de_entrenamiento\n",
        "\n",
        "# No he encontrado diferencia sustancial entre sdpa y xformers.\n",
        "atenci√≥n_cruzada = \"sdpa\"\n",
        "mixed_precision = \"fp16\"\n",
        "cross_attention = atenci√≥n_cruzada\n",
        "\n",
        "# Cachear los latentes en Drive a√±adir√° un archivo de 250KB junto a cada imagen pero usar√° considerablemente menos memoria.\n",
        "cache_latents = True\n",
        "cache_latents_to_drive = True\n",
        "cache_text_encoder_outputs = False\n",
        "\n",
        "#@markdown ### **Avanzado**\n",
        "#@markdown El optimizador es el algoritmo usado para entrenar. AdamW8Bit es el predeterminado y funciona muy bien, mientras que Prodigy\n",
        "#@markdown ajusta autom√°ticamente la tasa de aprendizaje y puede tener varias ventajas como entrenar m√°s r√°pido debido a necesitar menos pasos, adem√°s de funcionar mejor para datasets peque√±os.\n",
        "Optimizador = \"AdamW8bit\"  #@param [\"AdamW8bit\", \"Prodigy\", \"DAdaptation\", \"DadaptAdam\", \"DadaptLion\", \"AdamW\", \"Lion\", \"SGDNesterov\", \"SGDNesterov8bit\", \"AdaFactor\"]\n",
        "optimizer = Optimizador\n",
        "optimizer_args = [a.strip() for a in \"weight_decay=0.1 betas=[0.9,0.99]\".split(' ') if a]\n",
        "recommended_values = False\n",
        "\n",
        "if any(opt in optimizer.lower() for opt in [\"dadapt\", \"prodigy\"]):\n",
        "    if recommended_values:\n",
        "        unet_lr = text_encoder_lr = 0.75\n",
        "        network_alpha = network_dim\n",
        "elif \"CAME\" in optimizer:\n",
        "    optimizer, lr_scheduler = \"CAME\", \"REX\"\n",
        "    if recommended_values:\n",
        "        unet_lr, text_encoder_lr = 1e-4, 1e-6\n",
        "        optimizer_args = [arg for arg in optimizer_args if \"betas\" not in arg]\n",
        "\n",
        "lr_scheduler_num_cycles = lr_scheduler_number if lr_scheduler == \"cosine_with_restarts\" else 0\n",
        "lr_scheduler_power = lr_scheduler_number if lr_scheduler == \"polynomial\" else 0\n",
        "\n",
        "# üë©‚Äçüíª C√≥digo principal\n",
        "root_dir = \"/content\" if COLAB else pathlib.Path.home() / \"Loras\"\n",
        "deps_dir = os.path.join(root_dir, \"deps\")\n",
        "repo_dir = os.path.join(root_dir, \"kohya-trainer\")\n",
        "\n",
        "drive = \"/content/drive/MyDrive\"\n",
        "kohya_root = \"/content/kohya-files\"\n",
        "\n",
        "drive_dataset = os.path.join(drive, \"Loras\", ruta_files, \"dataset\")\n",
        "output_folder = os.path.join(drive, \"Loras\", ruta_files, \"models\")\n",
        "\n",
        "log_folder    = os.path.join(kohya_root, \"logs\")\n",
        "config_folder = os.path.join(kohya_root, \"config\")\n",
        "images_folder = os.path.join(kohya_root, \"Lora\", project_name, \"dataset\")\n",
        "\n",
        "# Archivos de configuraci√≥n\n",
        "config_file            = os.path.join(config_folder, \"training_config.toml\")\n",
        "dataset_config_file    = os.path.join(config_folder, \"dataset_config.toml\")\n",
        "accelerate_config_file = os.path.join(repo_dir, \"accelerate_config\", \"config.yaml\")\n",
        "\n",
        "def copy_dataset_to_local():\n",
        "    local_root = os.path.join(kohya_root, \"Lora\", project_name)\n",
        "    local_zip  = os.path.join(kohya_root, \"dataset.zip\")\n",
        "    drive_root = os.path.join(drive, \"Loras\", ruta_files)\n",
        "    drive_zip  = os.path.join(drive_root, \"dataset.zip\")\n",
        "\n",
        "    # Cancelar si el dataset YA tiene im√°genes\n",
        "    if os.path.exists(images_folder):\n",
        "        for f in os.listdir(images_folder):\n",
        "            if f.lower().endswith((\".png\", \".jpg\", \".txt\")):\n",
        "                return\n",
        "\n",
        "    # Crear ZIP en Drive si no existe\n",
        "    os.makedirs(local_root, exist_ok=True)\n",
        "    if not os.path.exists(drive_zip):\n",
        "        !cd \"{drive_root}\" && zip -r dataset.zip dataset\n",
        "\n",
        "    # Preparando ZIP a entorno local\n",
        "    clear_output()\n",
        "    print(\"üöö Moviendo ZIP a entorno local...\")\n",
        "    !mv \"{drive_zip}\" \"{local_zip}\"\n",
        "    !unzip -q \"{local_zip}\" -d \"{local_root}\"\n",
        "    !rm \"{local_zip}\"\n",
        "    print(\"üêù Dataset listo en entorno local\")\n",
        "\n",
        "def install_dependencies():\n",
        "  os.chdir(root_dir)\n",
        "  !git clone {SOURCE} {repo_dir}\n",
        "  os.chdir(repo_dir)\n",
        "  if COMMIT:\n",
        "    !git reset --hard {COMMIT}\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/train_network_xl_wrapper.py -q -O train_network_xl_wrapper.py\n",
        "  !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/dracula.py -q -O dracula.py\n",
        "\n",
        "  !apt -y update -qq\n",
        "  !apt -y install aria2 -qq\n",
        "  !export RUSTFLAGS=\"-A invalid_reference_casting\"\n",
        "  !pip install accelerate==0.19.0 transformers==4.30.2 diffusers==0.18.2 \\\n",
        "    bitsandbytes==0.45.1 flax==0.7.5 opencv-python jax==0.4.23 jaxlib==0.4.23 \\\n",
        "    pytorch-lightning==1.9.0 voluptuous==0.13.1 toml==0.10.2 ftfy==6.1.1 einops==0.6.0 \\\n",
        "    safetensors pygments huggingface-hub==0.22.0 wandb invisible-watermark==0.2.0 open-clip-torch==2.20.0 \\\n",
        "    dadaptation==3.1 prodigyopt==1.0 lion-pytorch==0.1.2 \\\n",
        "    torch==2.5.1+cu121 --extra-index https://download.pytorch.org/whl/cu121\n",
        "  !pip install -e .\n",
        "  if cross_attention == \"xformers\":\n",
        "    !pip install -q xformers\n",
        "  if \"CAME\" in optimizer:\n",
        "    !pip install came-pytorch\n",
        "    !wget https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/train_util.py -q -O library/train_util.py\n",
        "\n",
        "  # parchear kohya para peque√±os ajustes\n",
        "  if LOWRAM:\n",
        "    !sed -i \"s@cpu@cuda@\" library/model_util.py\n",
        "  if LOAD_TRUNCATED_IMAGES:\n",
        "    !sed -i 's/from PIL import Image/from PIL import Image, ImageFile\\nImageFile.LOAD_TRUNCATED_IMAGES=True/g' library/train_util.py # corregir error de jpegs truncados\n",
        "  if BETTER_EPOCH_NAMES:\n",
        "    !sed -i 's/{:06d}/{:02d}/g' library/train_util.py # hacer nombres de √©poca m√°s cortos\n",
        "    !sed -i 's/\".\" + args.save_model_as)/\"-{:02d}.\".format(num_train_epochs) + args.save_model_as)/g' train_network.py # el nombre de la √∫ltima √©poca coincidir√° con las dem√°s\n",
        "\n",
        "  from accelerate.utils import write_basic_config\n",
        "  if not os.path.exists(accelerate_config_file):\n",
        "    write_basic_config(save_location=accelerate_config_file)\n",
        "\n",
        "  os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "  os.environ[\"BITSANDBYTES_NOWELCOME\"] = \"1\"\n",
        "  os.environ[\"SAFETENSORS_FAST_GPU\"] = \"1\"\n",
        "  os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "def validate_dataset():\n",
        "  global lr_warmup_steps, lr_warmup_ratio, caption_extension, keep_tokens, model_url\n",
        "  supported_types = (\".png\", \".jpg\", \".jpeg\", \".webp\", \".bmp\")\n",
        "\n",
        "  if model_url.startswith(\"/content/drive/\") and not os.path.exists(model_url):\n",
        "    print(\"üí• Error: El modelo de entrenamiento personalizado que especificaste no se encontr√≥ en tu Google Drive.\")\n",
        "    return\n",
        "\n",
        "  print(\"\\nüíø Verificando dataset...\")\n",
        "  if not project_name.strip() or any(c in project_name for c in \" .()\\\"'\\\\/\"):\n",
        "    print(\"üí• Error: Por favor, elige un nombre de proyecto v√°lido.\")\n",
        "    return\n",
        "\n",
        "  # Encontrar las carpetas y archivos\n",
        "  if custom_dataset:\n",
        "    try:\n",
        "      datconf = toml.loads(custom_dataset)\n",
        "      datasets = [d for d in datconf[\"datasets\"][0][\"subsets\"]]\n",
        "    except:\n",
        "      print(f\"üí• Error: Tu dataset personalizado es inv√°lido o contiene un error. Revisa la plantilla original.\")\n",
        "      return\n",
        "    reg = [d.get(\"image_dir\") for d in datasets if d.get(\"is_reg\", False)]\n",
        "    datasets_dict = {d[\"image_dir\"]: d[\"num_repeats\"] for d in datasets}\n",
        "    folders = datasets_dict.keys()\n",
        "    files = [f for folder in folders for f in os.listdir(folder)]\n",
        "    images_repeats = {folder: (len([f for f in os.listdir(folder) if f.lower().endswith(supported_types)]), datasets_dict[folder]) for folder in folders}\n",
        "  else:\n",
        "    reg = []\n",
        "    folders = [images_folder]\n",
        "    files = os.listdir(images_folder)\n",
        "    images_repeats = {images_folder: (len([f for f in files if f.lower().endswith(supported_types)]), num_repeats)}\n",
        "\n",
        "# Validaci√≥n\n",
        "  for folder in folders:\n",
        "    if not os.path.exists(folder):\n",
        "      print(f\"üí• Error: La carpeta {folder.replace('/content/drive/', '')} no existe.\"); return\n",
        "\n",
        "  for folder, (img, _) in images_repeats.items():\n",
        "    if not img:\n",
        "      print(f\"üí• Error: Tu carpeta {folder.replace('/content/drive/', '')} est√° vac√≠a.\"); return\n",
        "\n",
        "  test_files = []\n",
        "  for f in files:\n",
        "    if not f.lower().endswith((caption_extension, \".npz\") + supported_types):\n",
        "      print(f\"üí• Error: Archivo inv√°lido en el dataset: \\\"{f}\\\". Abortando.\"); return\n",
        "    if any(f.endswith(supported_types) and ff.endswith(supported_types)\n",
        "           and os.path.splitext(f)[0] == os.path.splitext(ff)[0]\n",
        "           for ff in test_files):\n",
        "      print(f\"üí• Error: Los archivos {f} y {ff} no pueden tener el mismo nombre. Abortando.\"); return\n",
        "    test_files.append(f)\n",
        "\n",
        "  if caption_extension and not any(txt.lower().endswith(caption_extension) for txt in files):\n",
        "    caption_extension = \"\"\n",
        "  if continue_from_lora and not (continue_from_lora.endswith(\".safetensors\") and os.path.exists(continue_from_lora)):\n",
        "    print(\"üí• Error: Ruta inv√°lida para un Lora existente. Ejemplo: /content/drive/MyDrive/Loras/example.safetensors\"); return\n",
        "\n",
        "# Cosas bonitas\n",
        "  pre_steps_per_epoch = sum(img*rep for (img, rep) in images_repeats.values())\n",
        "  steps_per_epoch = pre_steps_per_epoch/train_batch_size\n",
        "  total_steps = max_train_steps or int(max_train_epochs*steps_per_epoch)\n",
        "  estimated_epochs = int(total_steps/steps_per_epoch)\n",
        "  lr_warmup_steps = int(total_steps*lr_warmup_ratio)\n",
        "\n",
        "  for folder, (img, rep) in images_repeats.items():\n",
        "    print(\"üìÅ\"+folder.replace(\"/content/drive/\", \"\") + (\" (Regularizaci√≥n)\" if folder in reg else \"\"))\n",
        "    print(f\"üìà Se encontraron {img} im√°genes con {rep} repeticiones, igualando {img*rep} pasos.\")\n",
        "  print(f\"üìâ Divide {pre_steps_per_epoch} pasos entre batch size {train_batch_size} para obtener {steps_per_epoch} pasos por √©poca.\")\n",
        "  if max_train_epochs:\n",
        "    print(f\"üîÆ Habr√° {max_train_epochs} √©pocas, para alrededor de {total_steps} pasos totales de entrenamiento.\")\n",
        "  else:\n",
        "    print(f\"üîÆ Habr√° {total_steps} pasos, divididos en {estimated_epochs} √©pocas y algunos m√°s.\")\n",
        "\n",
        "  if total_steps > 9999:\n",
        "    print(\"üí• Error: El total de pasos es demasiado alto. Probablemente cometiste un error. Abortando...\")\n",
        "    return\n",
        "\n",
        "  return True\n",
        "\n",
        "def create_config():\n",
        "  global dataset_config_file, config_file, model_file\n",
        "\n",
        "  if override_config_file:\n",
        "    config_file = override_config_file\n",
        "    print(f\"\\n‚≠ï Usando archivo de configuraci√≥n personalizado {config_file}\")\n",
        "  else:\n",
        "    config_dict = {\n",
        "      \"network_arguments\": {\n",
        "        \"unet_lr\": unet_lr,\n",
        "        \"text_encoder_lr\": text_encoder_lr if not cache_text_encoder_outputs else 0,\n",
        "        \"network_dim\": network_dim,\n",
        "        \"network_alpha\": network_alpha,\n",
        "        \"network_module\": network_module,\n",
        "        \"network_args\": network_args,\n",
        "        \"network_train_unet_only\": text_encoder_lr == 0 or cache_text_encoder_outputs,\n",
        "        \"network_weights\": continue_from_lora if continue_from_lora else None\n",
        "      },\n",
        "      \"optimizer_arguments\": {\n",
        "        \"learning_rate\": unet_lr,\n",
        "        \"lr_scheduler\": lr_scheduler,\n",
        "        \"lr_scheduler_num_cycles\": lr_scheduler_num_cycles if lr_scheduler == \"cosine_with_restarts\" else None,\n",
        "        \"lr_scheduler_power\": lr_scheduler_power if lr_scheduler == \"polynomial\" else None,\n",
        "        \"lr_warmup_steps\": lr_warmup_steps if lr_scheduler != \"constant\" else None,\n",
        "        \"optimizer_type\": optimizer,\n",
        "        \"optimizer_args\": optimizer_args if optimizer_args else None,\n",
        "      },\n",
        "      \"training_arguments\": {\n",
        "        \"pretrained_model_name_or_path\": model_file,\n",
        "        \"vae\": vae_file,\n",
        "        \"max_train_steps\": max_train_steps,\n",
        "        \"max_train_epochs\": max_train_epochs,\n",
        "        \"train_batch_size\": train_batch_size,\n",
        "        \"seed\": 42,\n",
        "        \"max_token_length\": 225,\n",
        "        \"xformers\": cross_attention == \"xformers\",\n",
        "        \"sdpa\": cross_attention == \"sdpa\",\n",
        "        \"min_snr_gamma\": min_snr_gamma if min_snr_gamma > 0 else None,\n",
        "        \"lowram\": LOWRAM,\n",
        "        \"no_half_vae\": True,\n",
        "        \"gradient_checkpointing\": True,\n",
        "        \"gradient_accumulation_steps\": 1,\n",
        "        \"max_data_loader_n_workers\": 8,\n",
        "        \"persistent_data_loader_workers\": True,\n",
        "        \"mixed_precision\": mixed_precision,\n",
        "        \"full_bf16\": mixed_precision == \"bf16\",\n",
        "        \"cache_latents\": cache_latents,\n",
        "        \"cache_latents_to_disk\": cache_latents_to_drive,\n",
        "        \"cache_text_encoder_outputs\": cache_text_encoder_outputs,\n",
        "        \"min_timestep\": 0,\n",
        "        \"max_timestep\": 1000,\n",
        "        \"prior_loss_weight\": 1.0,\n",
        "        \"multires_noise_iterations\": 6 if multinoise else None,\n",
        "        \"multires_noise_discount\": 0.3 if multinoise else None,\n",
        "      },\n",
        "      \"saving_arguments\": {\n",
        "        \"save_precision\": \"fp16\",\n",
        "        \"save_model_as\": \"safetensors\",\n",
        "        \"save_every_n_epochs\": save_every_n_epochs,\n",
        "        \"save_last_n_epochs\": keep_only_last_n_epochs,\n",
        "        \"output_name\": project_name,\n",
        "        \"output_dir\": output_folder,\n",
        "        \"log_prefix\": project_name,\n",
        "        \"logging_dir\": log_folder,\n",
        "        \"wandb_api_key\": None,\n",
        "        \"log_with\": None,\n",
        "      }\n",
        "    }\n",
        "\n",
        "    for key in config_dict:\n",
        "      if isinstance(config_dict[key], dict):\n",
        "        config_dict[key] = {k: v for k, v in config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(config_dict))\n",
        "    print(f\"\\nüìÑ Configuraci√≥n guardada en {config_file}\")\n",
        "\n",
        "  if override_dataset_config_file:\n",
        "    dataset_config_file = override_dataset_config_file\n",
        "    print(f\"‚≠ï Usando archivo de configuraci√≥n de dataset personalizado {dataset_config_file}\")\n",
        "  else:\n",
        "    dataset_config_dict = {\n",
        "      \"general\": {\n",
        "        \"resolution\": resolution,\n",
        "        \"shuffle_caption\": shuffle_caption and not cache_text_encoder_outputs,\n",
        "        \"keep_tokens\": keep_tokens,\n",
        "        \"flip_aug\": False,\n",
        "        \"caption_extension\": caption_extension,\n",
        "        \"enable_bucket\": True,\n",
        "        \"bucket_no_upscale\": False,\n",
        "        \"bucket_reso_steps\": 64,\n",
        "        \"min_bucket_reso\": 256,\n",
        "        \"max_bucket_reso\": 4096,\n",
        "      },\n",
        "      \"datasets\": toml.loads(custom_dataset)[\"datasets\"] if custom_dataset else [\n",
        "        {\n",
        "          \"subsets\": [\n",
        "            {\n",
        "              \"num_repeats\": num_repeats,\n",
        "              \"image_dir\": images_folder,\n",
        "              \"class_tokens\": None if caption_extension else project_name\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "\n",
        "    for key in dataset_config_dict:\n",
        "      if isinstance(dataset_config_dict[key], dict):\n",
        "        dataset_config_dict[key] = {k: v for k, v in dataset_config_dict[key].items() if v is not None}\n",
        "\n",
        "    with open(dataset_config_file, \"w\") as f:\n",
        "      f.write(toml.dumps(dataset_config_dict))\n",
        "    print(f\"üìÑ Configuraci√≥n del dataset guardada en {dataset_config_file}\")\n",
        "\n",
        "def download_model():\n",
        "  global old_model_url, model_url, model_file, vae_url, vae_file\n",
        "  real_model_url = model_url  # Hab√≠a una raz√≥n para tener una variable separada, pero la olvid√©.\n",
        "\n",
        "  if real_model_url.startswith(\"/content/drive/\"):\n",
        "    # Modelo local, ya se verific√≥ que existe\n",
        "    model_file = real_model_url\n",
        "    print(f\"üìÅ Usando archivo de modelo local: {model_file}\")\n",
        "    # Validaci√≥n\n",
        "    if model_file.lower().endswith(\".safetensors\"):\n",
        "      from safetensors.torch import load_file as load_safetensors\n",
        "      try:\n",
        "        test = load_safetensors(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        return False\n",
        "    elif model_file.lower().endswith(\".ckpt\"):\n",
        "      from torch import load as load_ckpt\n",
        "      try:\n",
        "        test = load_ckpt(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "  else:\n",
        "\n",
        "    # Modelo descargable\n",
        "    if load_diffusers:\n",
        "      if 'huggingface.co' in real_model_url:\n",
        "          match = re.search(r'huggingface\\.co/([^/]+)/([^/]+)', real_model_url)\n",
        "          if match:\n",
        "              username = match.group(1)\n",
        "              model_name = match.group(2)\n",
        "              model_file = f\"{username}/{model_name}\"\n",
        "              from huggingface_hub import HfFileSystem\n",
        "              fs = HfFileSystem()\n",
        "              existing_folders = set(fs.ls(model_file, detail=False))\n",
        "              necessary_folders = [ \"scheduler\", \"text_encoder\", \"text_encoder_2\", \"tokenizer\", \"tokenizer_2\", \"unet\", \"vae\" ]\n",
        "              if all(f\"{model_file}/{folder}\" in existing_folders for folder in necessary_folders):\n",
        "                print(\"üçÉ Modelo Diffusers identificado.\")  # Ser√° manejado por kohya\n",
        "                return True\n",
        "      raise ValueError(\"üí• Error al cargar el modelo Diffusers. Si este modelo no es Diffusers, ¬øhas intentado desactivarlo en la parte superior del Colab?\")\n",
        "\n",
        "    # Definir nombre de archivo local\n",
        "    if not model_file:\n",
        "      if real_model_url.lower().endswith((\".ckpt\", \".safetensors\")):\n",
        "        model_file = f\"/content{real_model_url[real_model_url.rfind('/'):]}\"\n",
        "      else:\n",
        "        model_file = \"/content/downloaded_model.safetensors\"\n",
        "        if os.path.exists(model_file):\n",
        "          !rm \"{model_file}\"\n",
        "\n",
        "    # HuggingFace\n",
        "    if m := re.search(r\"(?:https?://)?(?:www\\.)?huggingface\\.co/[^/]+/[^/]+/blob\", real_model_url):\n",
        "      real_model_url = real_model_url.replace(\"blob\", \"resolve\")\n",
        "    # Civitai\n",
        "    elif m := re.search(r\"(?:https?://)?(?:www\\\\.)?civitai\\.com/models/([0-9]+)(/[A-Za-z0-9-_]+)?\", real_model_url):\n",
        "      if m.group(2):\n",
        "        model_file = f\"/content{m.group(2)}.safetensors\"\n",
        "      if m := re.search(r\"modelVersionId=([0-9]+)\", real_model_url):\n",
        "        real_model_url = f\"https://civitai.com/api/download/models/{m.group(1)}\"\n",
        "      else:\n",
        "        raise ValueError(\"üí• optional_custom_training_model contiene un enlace de Civitai, pero no incluye un modelVersionId. Tambi√©n puedes hacer clic derecho en el bot√≥n de descarga y copiar el enlace directo.\")\n",
        "\n",
        "    # Descargar checkpoint\n",
        "    !aria2c \"{real_model_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{model_file}\"\n",
        "\n",
        "    # Descargar VAE\n",
        "    if not os.path.exists(vae_file):\n",
        "      !aria2c \"{vae_url}\" --console-log-level=warn -c -s 16 -x 16 -k 10M -d / -o \"{vae_file}\"\n",
        "\n",
        "    # Validaci√≥n\n",
        "\n",
        "    if model_file.lower().endswith(\".safetensors\"):\n",
        "      from safetensors.torch import load_file as load_safetensors\n",
        "      try:\n",
        "        test = load_safetensors(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        new_model_file = os.path.splitext(model_file)[0]+\".ckpt\"\n",
        "        !mv \"{model_file}\" \"{new_model_file}\"\n",
        "        model_file = new_model_file\n",
        "        print(f\"Renombrado modelo a {os.path.splitext(model_file)[0]}.ckpt\")\n",
        "\n",
        "    if model_file.lower().endswith(\".ckpt\"):\n",
        "      from torch import load as load_ckpt\n",
        "      try:\n",
        "        test = load_ckpt(model_file)\n",
        "        del test\n",
        "      except:\n",
        "        return False\n",
        "\n",
        "  return True\n",
        "\n",
        "def main():\n",
        "  global dependencies_installed\n",
        "\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"üìÇ Conectando a Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  for dir in (deps_dir, repo_dir, log_folder, config_folder, output_folder):\n",
        "      os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  copy_dataset_to_local()\n",
        "\n",
        "  if not validate_dataset():\n",
        "      return\n",
        "\n",
        "  if not dependencies_installed:\n",
        "    print(\"\\nüè≠ Instalando dependencias...\\n\")\n",
        "    t0 = time()\n",
        "    install_dependencies()\n",
        "    t1 = time()\n",
        "    dependencies_installed = True\n",
        "    print(f\"\\n‚úÖ Instalaci√≥n finalizada en {int(t1-t0)} segundos.\")\n",
        "  else:\n",
        "    print(\"\\n‚úÖ Dependencias ya instaladas.\")\n",
        "\n",
        "  if old_model_url != model_url or not model_file or not os.path.exists(model_file):\n",
        "    print(\"\\nüîÑ Obteniendo modelo...\")\n",
        "    if not download_model():\n",
        "      print(\"\\nüí• Error: El modelo especificado es inv√°lido o est√° corrupto.\"\n",
        "            \"\\nSi est√°s usando una URL, verifica que sea accesible sin iniciar sesi√≥n.\"\n",
        "            \"\\nPuedes usar URLs de Civitai o HuggingFace, o una ruta en tu Google Drive que comience con /content/drive/MyDrive\")\n",
        "      return\n",
        "    print()\n",
        "  else:\n",
        "    print(\"\\nüîÑ Modelo ya descargado.\\n\")\n",
        "\n",
        "  create_config()\n",
        "  clear_output()\n",
        "  print(\"\\n‚≠ê Iniciando entrenador...\\n\")\n",
        "  os.chdir(repo_dir)\n",
        "\n",
        "  !accelerate launch --quiet --config_file={accelerate_config_file} --num_cpu_threads_per_process=1 train_network_xl_wrapper.py --dataset_config={dataset_config_file} --config_file={config_file}\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    display(Markdown(\"### ‚úÖ ¬°Listo! [Ve a descargar tu Lora desde Google Drive](https://drive.google.com/drive/my-drive)\\n\"\n",
        "                     \"### Habr√° varios archivos, deber√≠as probar la √∫ltima versi√≥n (el archivo con el n√∫mero m√°s grande junto a √©l)\"))\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_MVUbePOBvN9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "re8AABXU-XNC",
        "55qNJITqJi3e",
        "4C6y8WtxJEsm",
        "pEmSPgVntqy6",
        "FPVDHX0Wqjaz",
        "y7yLmTCbfyob",
        "_59C1GsdpHqE",
        "fUHdPGRTnc3i",
        "SU4fxUHNnwo0",
        "MgLaj0Tb_S28"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}